from typing import List, Dict, Any, TypedDict
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from googlenews import GoogleNews
from web_scraper import NewsWebScraper
import operator
import dotenv
import json
import re
import os
from datetime import datetime, timedelta, timezone
import streamlit as st
import time
from urllib.parse import urlparse

import dotenv #pwc
dotenv.load_dotenv(override=True) #pwc

# í•œêµ­ ì‹œê°„ëŒ€(KST) ì •ì˜
KST = timezone(timedelta(hours=9))

# ìƒíƒœ íƒ€ì… ì •ì˜
class AgentState(TypedDict):
    news_data: List[dict]
    filtered_news: List[dict]
    analysis: str
    keyword: str
    system_prompt: str
    user_prompt: str
    excluded_news: List[dict]
    borderline_news: List[dict]
    retained_news: List[dict]
    grouped_news: List[dict]
    final_selection: List[dict]
    system_prompt_1: str
    user_prompt_1: str
    llm_response_1: str
    system_prompt_2: str
    user_prompt_2: str
    llm_response_2: str
    system_prompt_3: str
    user_prompt_3: str
    llm_response_3: str
    not_selected_news: List[dict]
    original_news_data: List[dict]
    start_datetime: datetime
    end_datetime: datetime

# ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ ëª©ë¡ (ê¸°ë³¸ê°’ìœ¼ë¡œë§Œ ì‚¬ìš©)
TRUSTED_PRESS_ALIASES = {
    "ì¡°ì„ ì¼ë³´": ["ì¡°ì„ ì¼ë³´", "chosun", "chosun.com"],
    "ì¤‘ì•™ì¼ë³´": ["ì¤‘ì•™ì¼ë³´", "joongang", "joongang.co.kr", "joins.com"],
    "ë™ì•„ì¼ë³´": ["ë™ì•„ì¼ë³´", "donga", "donga.com"],
    "ì¡°ì„ ë¹„ì¦ˆ": ["ì¡°ì„ ë¹„ì¦ˆ", "chosunbiz", "biz.chosun.com"],
    "í•œêµ­ê²½ì œ": ["í•œêµ­ê²½ì œ", "í•œê²½", "hankyung", "hankyung.com", "í•œê²½ë‹·ì»´"],
    "ë§¤ì¼ê²½ì œ": ["ë§¤ì¼ê²½ì œ", "ë§¤ê²½", "mk", "mk.co.kr"],
    "ì—°í•©ë‰´ìŠ¤": ["ì—°í•©ë‰´ìŠ¤", "yna", "yna.co.kr"],
    "íŒŒì´ë‚¸ì…œë‰´ìŠ¤": ["íŒŒì´ë‚¸ì…œë‰´ìŠ¤", "fnnews", "fnnews.com"],
    "ë°ì¼ë¦¬íŒœ": ["ë°ì¼ë¦¬íŒœ", "dailypharm", "dailypharm.com"],
    "ITì¡°ì„ ": ["itì¡°ì„ ", "it.chosun.com", "itchosun"],
    "ë¨¸ë‹ˆíˆ¬ë°ì´": ["ë¨¸ë‹ˆíˆ¬ë°ì´", "mt", "mt.co.kr"],
    "ë¹„ì¦ˆë‹ˆìŠ¤í¬ìŠ¤íŠ¸": ["ë¹„ì¦ˆë‹ˆìŠ¤í¬ìŠ¤íŠ¸", "businesspost", "businesspost.co.kr"],
    "ì´ë°ì¼ë¦¬": ["ì´ë°ì¼ë¦¬", "edaily", "edaily.co.kr"],
    "ì•„ì‹œì•„ê²½ì œ": ["ì•„ì‹œì•„ê²½ì œ", "asiae", "asiae.co.kr"],
    "ë‰´ìŠ¤í•Œ": ["ë‰´ìŠ¤í•Œ", "newspim", "newspim.com"],
    "ë‰´ì‹œìŠ¤": ["ë‰´ì‹œìŠ¤", "newsis", "newsis.com"],
    "í—¤ëŸ´ë“œê²½ì œ": ["í—¤ëŸ´ë“œê²½ì œ", "herald", "heraldcorp", "heraldcorp.com"]
}

# í—¬í¼ í•¨ìˆ˜: LLM í˜¸ì¶œ
def call_llm(state: AgentState, system_prompt: str, user_prompt: str, stage: int = 1) -> str:
    """LLMì„ í˜¸ì¶œí•˜ê³  ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # LLM ì´ˆê¸°í™”
        llm = ChatOpenAI(
           # openai_api_key=os.getenv("OPENAI_API_KEY"), #pwc
            #openai_api_base=os.getenv("OPENAI_BASE_URL"), #pwc
            #model_name = "openai.gpt-4.1-2025-04-14",
            model_name=state.get("model", "gpt-5"),
            temperature=0.1,
            #max_tokens=2000
        )

        # ë©”ì‹œì§€ êµ¬ì„±
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ]

        # í”„ë¡¬í”„íŠ¸ ì €ì¥
        if stage == 1:
            state["system_prompt_1"] = system_prompt
            state["user_prompt_1"] = user_prompt
        elif stage == 2:
            state["system_prompt_2"] = system_prompt
            state["user_prompt_2"] = user_prompt
        elif stage == 3:
            state["system_prompt_3"] = system_prompt
            state["user_prompt_3"] = user_prompt

        # ë””ë²„ê·¸ ì¶œë ¥
        print(f"\n=== {stage}ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ===")
        print("\n[System Prompt]:")
        print(system_prompt)
        print("\n[User Prompt]:")
        print(user_prompt)

        # LLM í˜¸ì¶œ
        result = llm.invoke(messages).content
        
        # ì‘ë‹µ ì €ì¥
        if stage == 1:
            state["llm_response_1"] = result
        elif stage == 2:
            state["llm_response_2"] = result
        elif stage == 3:
            state["llm_response_3"] = result
            
        print(f"\n=== {stage}ë‹¨ê³„: LLM ì‘ë‹µ ===")
        print(result)
        
        return result
    
    except Exception as e:
        st.error(f"LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return ""

# í—¬í¼ í•¨ìˆ˜: JSON íŒŒì‹±
def parse_json_response(response: str) -> dict:
    """LLM ì‘ë‹µì—ì„œ JSONì„ ì¶”ì¶œí•˜ê³  íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ì½”ë“œ ë¸”ë¡ ì œê±°
        if response.startswith("```json"):
            response = response[7:]
        if response.startswith("```"):
            # ì²« ì¤„ ì œê±° (```json ë˜ëŠ” ``` ì œê±°)
            response = "\n".join(response.split("\n")[1:])
        if response.endswith("```"):
            # ë§ˆì§€ë§‰ ì¤„ ì œê±°
            response = "\n".join(response.split("\n")[:-1])
        
        # ì•ë’¤ ê³µë°± ì œê±°
        response = response.strip()
        
        # JSON ì‹œì‘/ë í™•ì¸
        if not response.startswith("{"):
            response = "{" + response
        if not response.endswith("}"):
            response = response + "}"
        
        # ì¤‘ê´„í˜¸ ìŒì´ ë§ëŠ”ì§€ í™•ì¸
        open_braces = response.count("{")
        close_braces = response.count("}")
        if open_braces > close_braces:
            response = response + "}" * (open_braces - close_braces)
        elif close_braces > open_braces:
            response = "{" * (close_braces - open_braces) + response
        
        # JSON íŒŒì‹±
        return json.loads(response)
    
    except json.JSONDecodeError as e:
        print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        print(f"ì›ë³¸ ì‘ë‹µ: {response}")
        raise e

# ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° í•¨ìˆ˜
def collect_news(state: AgentState) -> AgentState:
    """ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ê²€ìƒ‰ì–´ ì„¤ì • - ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
        keyword = state.get("keyword", "ì‚¼ì„±")
        
        # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ëŠ” í•­ìƒ 100ê°œ
        max_results = 100
        
        # ë‚ ì§œ ë²”ìœ„ ê°€ì ¸ì˜¤ê¸°
        start_datetime = state.get("start_datetime")
        end_datetime = state.get("end_datetime")
        
        # GoogleNews ê°ì²´ ìƒì„±
        news = GoogleNews()
        
        # keywordê°€ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜, ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if isinstance(keyword, str):
            keywords_to_search = [keyword]
        else:
            keywords_to_search = keyword
        
        # ëª¨ë“  í‚¤ì›Œë“œì— ëŒ€í•œ ë‰´ìŠ¤ ìˆ˜ì§‘
        all_news_data = []
        
        # í‚¤ì›Œë“œ ì–¸ì–´ë³„ ì§€ì—­ ë§¤í•‘
        def is_korean_keyword(keyword):
            """í•œêµ­ì–´ í‚¤ì›Œë“œì¸ì§€ íŒë‹¨"""
            # í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ í•œêµ­ì–´ í‚¤ì›Œë“œ
            return bool(re.search(r'[ê°€-í£]', keyword))
        
        def get_target_regions(keyword):
            """í‚¤ì›Œë“œì— ë”°ë¥¸ ëŒ€ìƒ ì§€ì—­ ë°˜í™˜"""
            # ëª¨ë“  í‚¤ì›Œë“œì— ëŒ€í•´ ë¯¸êµ­ì—ì„œë§Œ ê²€ìƒ‰
            return ["ë¯¸êµ­","ì¼ë³¸"]
        
        # ê° í‚¤ì›Œë“œë³„ë¡œ ë‰´ìŠ¤ ê²€ìƒ‰ ë° ê²°ê³¼ ë³‘í•© (ì–¸ì–´ë³„ ì§€ì—­ ìµœì í™”)
        for kw in keywords_to_search:
            target_regions = get_target_regions(kw)
            keyword_type = "í•œêµ­ì–´" if is_korean_keyword(kw) else "ì˜ì–´"
            
            print(f"í‚¤ì›Œë“œ '{kw}' ({keyword_type}) ê²€ìƒ‰ ì¤‘... ëŒ€ìƒ ì§€ì—­: {', '.join(target_regions)}")
            
            # ê° ëŒ€ìƒ ì§€ì—­ì—ì„œ ë‰´ìŠ¤ ê²€ìƒ‰
            keyword_results = []
            for region in target_regions:
                region_results = news.search_by_keyword(kw, k=max_results//len(target_regions), region=region)
                keyword_results.extend(region_results)
                print(f"  - {region}ì—ì„œ {len(region_results)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘")
            
            all_news_data.extend(keyword_results)
            print(f"í‚¤ì›Œë“œ '{kw}' ì´ ê²€ìƒ‰ ê²°ê³¼: {len(keyword_results)}ê°œ")
            
            # ì§€ì—­ë³„ ë¶„í¬ ì¶œë ¥
            region_count = {}
            for item in keyword_results:
                region = item.get("region", "ì•Œ ìˆ˜ ì—†ìŒ")
                region_count[region] = region_count.get(region, 0) + 1
            
            if region_count:
                region_summary = ", ".join([f"{region}:{count}" for region, count in region_count.items()])
                print(f"  ì§€ì—­ë³„ ë¶„í¬: {region_summary}")
        
        # ì¤‘ë³µ URL ì œê±° (ê°™ì€ URLì´ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼)
        unique_urls = set()
        unique_news_data = []
        
        for news_item in all_news_data:
            url = news_item.get('url', '')
            if url and url not in unique_urls:
                unique_urls.add(url)
                unique_news_data.append(news_item)
        
        print(f"ì¤‘ë³µ ì œê±° í›„ ì „ì²´ ë‰´ìŠ¤ ìˆ˜: {len(unique_news_data)}ê°œ")
        
        # ìˆ˜ì§‘ëœ ë‰´ìŠ¤ì˜ ì²« ëª‡ ê°œ ìƒ˜í”Œ ì¶œë ¥
        print(f"\n=== ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ) ===")
        for i, news in enumerate(unique_news_data[:5], 1):
            print(f"{i}. ì œëª©: {news.get('content', 'ì œëª© ì—†ìŒ')}")
            print(f"   ì–¸ë¡ ì‚¬: {news.get('press', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
            print(f"   ì§€ì—­: {news.get('region', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
            print(f"   ë‚ ì§œ: {news.get('date', 'ë‚ ì§œ ì—†ìŒ')}")
            print(f"   URL: {news.get('url', 'URL ì—†ìŒ')[:80]}...")
            print("---")
        
        # ë‚ ì§œ í•„í„°ë§
        if start_datetime and end_datetime:
            print(f"\n=== ë‚ ì§œ í•„í„°ë§ ì‹œì‘ ===")
            print(f"í•„í„°ë§ ë²”ìœ„: {start_datetime} ~ {end_datetime}")
            
            filtered_news = []
            date_parsing_stats = {
                "total": len(unique_news_data),
                "no_date": 0,
                "parse_success": 0,
                "parse_failed": 0,
                "in_range": 0,
                "out_of_range": 0
            }
            
            for news_item in unique_news_data:
                try:
                    # ë‰´ìŠ¤ ë‚ ì§œ íŒŒì‹±
                    news_date_str = news_item.get('date', '')
                    if not news_date_str:
                        date_parsing_stats["no_date"] += 1
                        # ë‚ ì§œ ì •ë³´ê°€ ì—†ëŠ” ë‰´ìŠ¤ëŠ” í¬í•¨ (ìµœì‹  ë‰´ìŠ¤ì¼ ê°€ëŠ¥ì„±)
                        filtered_news.append(news_item)
                        continue
                    
                    news_date = None
                    
                    # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬ (ìš°ì„ ìˆœìœ„ ìˆœ)
                    date_formats = [
                        '%a, %d %b %Y %H:%M:%S %Z',      # GMT í˜•ì‹: Mon, 01 Jan 2024 12:00:00 GMT
                        '%a, %d %b %Y %H:%M:%S GMT',     # GMT í˜•ì‹ (ëª…ì‹œì )
                        '%Y-%m-%d %H:%M:%S',             # YYYY-MM-DD HH:MM:SS
                        '%Y-%m-%d',                      # YYYY-MM-DD
                        '%Yë…„ %mì›” %dì¼',                # í•œêµ­ì–´ í˜•ì‹
                        '%m/%d/%Y',                      # MM/DD/YYYY
                        '%d/%m/%Y',                      # DD/MM/YYYY
                        '%Y.%m.%d',                      # YYYY.MM.DD
                        '%m.%d.%Y',                      # MM.DD.YYYY
                    ]
                    
                    for date_format in date_formats:
                        try:
                            news_date = datetime.strptime(news_date_str, date_format)
                            break
                        except ValueError:
                            continue
                    
                    if news_date is None:
                        date_parsing_stats["parse_failed"] += 1
                        print(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: '{news_date_str}' - í¬í•¨í•˜ì—¬ ì²˜ë¦¬")
                        # íŒŒì‹± ì‹¤íŒ¨í•œ ë‰´ìŠ¤ë„ í¬í•¨ (ìµœì‹  ë‰´ìŠ¤ì¼ ê°€ëŠ¥ì„±)
                        filtered_news.append(news_item)
                        continue
                    
                    date_parsing_stats["parse_success"] += 1
                    
                    # GMT ì‹œê°„ëŒ€ ë³€í™˜ ì „ ë‚ ì§œ ê¸°ë¡
                    original_news_date = news_date
                    
                    # ì‹œê°„ëŒ€ ì²˜ë¦¬: GMT ì‹œê°„ì„ í•œêµ­ ì‹œê°„(KST)ìœ¼ë¡œ ë³€í™˜
                    if 'GMT' in news_date_str or 'Z' in news_date_str:
                        # GMT ì‹œê°„ì— 9ì‹œê°„ ì¶”ê°€í•˜ì—¬ KSTë¡œ ë³€í™˜
                        news_date = news_date + timedelta(hours=9)
                        # ì²« ëª‡ ê°œ ë‰´ìŠ¤ì— ëŒ€í•´ì„œë§Œ ë³€í™˜ ì •ë³´ ì¶œë ¥
                        if date_parsing_stats["parse_success"] <= 3:
                            print(f"GMTâ†’KST ë³€í™˜: {original_news_date} â†’ {news_date}")
                    
                    # íŒŒì‹±ëœ ë‚ ì§œì— KST ì‹œê°„ëŒ€ ì¶”ê°€ (ì‹œê°„ëŒ€ê°€ ì—†ëŠ” ê²½ìš°)
                    if news_date.tzinfo is None:
                        news_date = news_date.replace(tzinfo=KST)
                    
                    # ì‹œê°„ê¹Œì§€ ê³ ë ¤í•œ ì •í™•í•œ ë²”ìœ„ ì²´í¬ (08:00 ê¸°ì¤€)
                    if start_datetime <= news_date <= end_datetime:
                        date_parsing_stats["in_range"] += 1
                        filtered_news.append(news_item)
                    else:
                        date_parsing_stats["out_of_range"] += 1
                        # ë²”ìœ„ ì™¸ ë‰´ìŠ¤ ì¤‘ ì²« ëª‡ ê°œë§Œ ì¶œë ¥
                        if date_parsing_stats["out_of_range"] <= 3:
                            print(f"ì‹œê°„ ë²”ìœ„ ì™¸: {news_date} (ë²”ìœ„: {start_datetime} ~ {end_datetime})")
                        
                except Exception as e:
                    date_parsing_stats["parse_failed"] += 1
                    print(f"ë‚ ì§œ ì²˜ë¦¬ ì˜¤ë¥˜: {e} - ë‰´ìŠ¤ í¬í•¨í•˜ì—¬ ì²˜ë¦¬")
                    # ì˜¤ë¥˜ ë°œìƒí•œ ë‰´ìŠ¤ë„ í¬í•¨
                    filtered_news.append(news_item)
                    continue
            
            unique_news_data = filtered_news
            
            # ë‚ ì§œ í•„í„°ë§ í†µê³„ ì¶œë ¥
            print(f"\n=== ë‚ ì§œ í•„í„°ë§ í†µê³„ ===")
            print(f"ì „ì²´ ë‰´ìŠ¤: {date_parsing_stats['total']}ê°œ")
            print(f"ë‚ ì§œ ì •ë³´ ì—†ìŒ: {date_parsing_stats['no_date']}ê°œ")
            print(f"ë‚ ì§œ íŒŒì‹± ì„±ê³µ: {date_parsing_stats['parse_success']}ê°œ")
            print(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_parsing_stats['parse_failed']}ê°œ")
            print(f"ë‚ ì§œ ë²”ìœ„ ë‚´: {date_parsing_stats['in_range']}ê°œ")
            print(f"ë‚ ì§œ ë²”ìœ„ ì™¸: {date_parsing_stats['out_of_range']}ê°œ")
            print(f"ìµœì¢… í•„í„°ë§ëœ ë‰´ìŠ¤: {len(unique_news_data)}ê°œ")
        
        # ì›ë˜ ì¸ë±ìŠ¤ ì¶”ê°€
        for i, news_item in enumerate(unique_news_data, 1):
            news_item['original_index'] = i
        
        # ì›ë³¸ ë‰´ìŠ¤ ë°ì´í„° ì €ì¥
        state["original_news_data"] = unique_news_data.copy()
        # í•„í„°ë§í•  ë‰´ìŠ¤ ë°ì´í„° ì €ì¥
        state["news_data"] = unique_news_data
        
        # ë‚ ì§œ í•„í„°ë§ ê²°ê³¼ ì¶œë ¥
        print(f"\në‚ ì§œ í•„í„°ë§ ê²°ê³¼:")
        print(f"ì‹œì‘ ë‚ ì§œ: {start_datetime}")
        print(f"ì¢…ë£Œ ë‚ ì§œ: {end_datetime}")
        print(f"í•„í„°ë§ëœ ë‰´ìŠ¤ ìˆ˜: {len(unique_news_data)}")
        
        return state
    except Exception as e:
        print(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return state

def filter_valid_press(state: AgentState) -> AgentState:
    """ìœ íš¨ ì–¸ë¡ ì‚¬ í•„í„°ë§ - ê¸€ë¡œë²Œ ë‰´ìŠ¤ ìˆ˜ì§‘ì„ ìœ„í•´ ë¹„í™œì„±í™”"""
    news_data = state.get("news_data", [])
    
    print(f"\nì „ì²´ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ìˆ˜: {len(news_data)}")
    print("ğŸŒ ê¸€ë¡œë²Œ ë‰´ìŠ¤ ìˆ˜ì§‘ì„ ìœ„í•´ ì–¸ë¡ ì‚¬ í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    print("ëª¨ë“  ì–¸ë¡ ì‚¬ì˜ ë‰´ìŠ¤ê°€ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.")
    
    # ì–¸ë¡ ì‚¬ í•„í„°ë§ ì—†ì´ ëª¨ë“  ë‰´ìŠ¤ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬
    print(f"\nìœ íš¨ ì–¸ë¡ ì‚¬ í•„í„°ë§ ê±´ë„ˆëœ€: {len(news_data)}ê°œ ë‰´ìŠ¤ ëª¨ë‘ ì „ë‹¬")
    
    # ê° ë‰´ìŠ¤ì— ì§€ì—­ ì •ë³´ê°€ ìˆë‹¤ë©´ í‘œì‹œ
    region_count = {}
    for news in news_data:
        region = news.get("region", "ì•Œ ìˆ˜ ì—†ìŒ")
        if region in region_count:
            region_count[region] += 1
        else:
            region_count[region] = 1
    
    if region_count:
        print("\n=== ì§€ì—­ë³„ ë‰´ìŠ¤ ë¶„í¬ ===")
        for region, count in region_count.items():
            print(f"- {region}: {count}ê°œ ê¸°ì‚¬")
    
    # state ì—…ë°ì´íŠ¸ (ëª¨ë“  ë‰´ìŠ¤ ê·¸ëŒ€ë¡œ ì „ë‹¬)
    state["news_data"] = news_data
    return state

def filter_valid_press_original(state: AgentState) -> AgentState:
    """ìœ íš¨ ì–¸ë¡ ì‚¬ í•„í„°ë§ - ì›ë³¸ í•¨ìˆ˜ (í•„ìš”ì‹œ ë³µêµ¬ìš©)"""
    news_data = state.get("news_data", [])
    
    # UIì—ì„œ ì„¤ì •í•œ ìœ íš¨ ì–¸ë¡ ì‚¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    valid_press_dict_str = state.get("valid_press_dict", "")
    
    # UI ì„¤ì • ê°’ì´ ë¬¸ìì—´ì´ë©´ ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹±
    valid_press_config = {}
    if isinstance(valid_press_dict_str, str) and valid_press_dict_str.strip():
        print("\n[DEBUG] UIì—ì„œ ì„¤ì •í•œ ì–¸ë¡ ì‚¬ ë¬¸ìì—´ íŒŒì‹± ì‹œì‘")
        try:
            # ë¬¸ìì—´ì—ì„œ ë”•ì…”ë„ˆë¦¬ íŒŒì‹±
            lines = valid_press_dict_str.strip().split('\n')
            for line in lines:
                line = line.strip()
                if line and ': ' in line:
                    press_name, aliases_str = line.split(':', 1)
                    try:
                        # ë¬¸ìì—´ í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                        aliases = eval(aliases_str.strip())
                        valid_press_config[press_name.strip()] = aliases
                        print(f"[DEBUG] íŒŒì‹± ì„±ê³µ: {press_name.strip()} -> {aliases}")
                    except Exception as e:
                        print(f"[DEBUG] íŒŒì‹± ì‹¤íŒ¨: {line}, ì˜¤ë¥˜: {str(e)}")
        except Exception as e:
            print(f"[DEBUG] ì „ì²´ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
    # UI ì„¤ì • ê°’ì´ ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    elif isinstance(valid_press_dict_str, dict):
        valid_press_config = valid_press_dict_str
        print("\n[DEBUG] UIì—ì„œ ì„¤ì •í•œ ì–¸ë¡ ì‚¬ ë”•ì…”ë„ˆë¦¬ ì§ì ‘ ì‚¬ìš©")
    
    # íŒŒì‹± ê²°ê³¼ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    if not valid_press_config:
        print("\n[DEBUG] ìœ íš¨í•œ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©")
        valid_press_config = TRUSTED_PRESS_ALIASES

    return state

# ì¶”ê°€ ë‹¨ê³„: ì„ ì •ëœ ë‰´ìŠ¤ ì›ë¬¸ ìš”ì•½
def summarize_selected_articles(state: AgentState) -> AgentState:
    """ì„ ì •ëœ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì›ë¬¸ì„ ìŠ¤í¬ë˜í•‘í•˜ê³  ìš”ì•½"""
    try:
        final_selection = state.get("final_selection", [])
        
        if not final_selection:
            print("ìš”ì•½í•  ì„ ì •ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return state
        
        print(f"\n=== ì„ ì •ëœ {len(final_selection)}ê°œ ê¸°ì‚¬ ì›ë¬¸ ìš”ì•½ ì‹œì‘ ===")
        
        # í•˜ì´ë¸Œë¦¬ë“œ ì›¹ ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™” (AI í´ë°± í™œì„±í™”)
        from web_scraper import HybridNewsWebScraper
        import os
        
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
        openai_api_key = os.getenv('OPENAI_API_KEY')
        scraper = HybridNewsWebScraper(
            openai_api_key=openai_api_key,
            enable_ai_fallback=True  # AI í´ë°± í™œì„±í™”
        )
        
        # ê° ì„ ì •ëœ ë‰´ìŠ¤ì˜ ì›ë¬¸ ì¶”ì¶œ ë° ìš”ì•½
        summarized_articles = []
        
        for i, news in enumerate(final_selection, 1):
            url = news.get('url', '')
            title = news.get('title', '')
            
            print(f"\n[{i}/{len(final_selection)}] ê¸°ì‚¬ ì›ë¬¸ ì¶”ì¶œ ì¤‘: {title}")
            
            # ì›ë¬¸ ì¶”ì¶œ (ìƒˆë¡œìš´ ExtractionResult ê°ì²´ ë°˜í™˜)
            extraction_result = scraper.extract_content(url, timeout=15)
            
            if extraction_result.success and extraction_result.content:
                # AI ìš”ì•½ ìƒì„±
                summary = _generate_article_summary(
                    extraction_result.content, 
                    title, 
                    state.get("system_prompt_3", "")
                )
                
                # ìš”ì•½ ê²°ê³¼ ì¶”ê°€
                news_with_summary = news.copy()
                news_with_summary['full_content'] = extraction_result.content
                news_with_summary['ai_summary'] = summary
                news_with_summary['extraction_success'] = True
                news_with_summary['extraction_method'] = extraction_result.method.value
                news_with_summary['extraction_time'] = extraction_result.extraction_time
                
                summarized_articles.append(news_with_summary)
                print(f"âœ… ìš”ì•½ ì™„ë£Œ: {title[:50]}... (ë°©ë²•: {extraction_result.method.value})")
                
            else:
                # ì›ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨
                error_msg = extraction_result.error_message if extraction_result else "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
                news_with_summary = news.copy()
                news_with_summary['full_content'] = ""
                news_with_summary['ai_summary'] = f"ì›ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨ë¡œ ìš”ì•½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({error_msg})"
                news_with_summary['extraction_success'] = False
                news_with_summary['extraction_method'] = extraction_result.method.value if extraction_result else "unknown"
                news_with_summary['extraction_time'] = extraction_result.extraction_time if extraction_result else 0
                
                summarized_articles.append(news_with_summary)
                print(f"âŒ ì›ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: {title[:50]}... ({error_msg})")
            
            # ìš”ì²­ ê°„ ì§€ì—° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
            if i < len(final_selection):
                time.sleep(1)
        
        # ê²°ê³¼ ì—…ë°ì´íŠ¸
        state["final_selection"] = summarized_articles
        
        print(f"\nì›ë¬¸ ìš”ì•½ ì™„ë£Œ: {len(summarized_articles)}ê°œ ê¸°ì‚¬")
        success_count = sum(1 for article in summarized_articles if article.get('extraction_success', False))
        print(f"ì„±ê³µ: {success_count}ê°œ, ì‹¤íŒ¨: {len(summarized_articles) - success_count}ê°œ")
        
        return state
        
    except Exception as e:
        print(f"ê¸°ì‚¬ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return state

def _generate_article_summary(content: str, title: str, system_prompt: str) -> str:
    """AIë¥¼ ì‚¬ìš©í•´ ê¸°ì‚¬ ìš”ì•½ ìƒì„±"""
    try:
        # ìš”ì•½ í”„ë¡¬í”„íŠ¸ ë¨¼ì € ì •ì˜
        summary_prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ í˜„ëŒ€ìë™ì°¨ ë‚¨ì–‘ì—°êµ¬ì†Œ PT/ì „ë™í™” ê°œë°œ ì¸ë ¥ ê´€ì ì—ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”.

[ê¸°ì‚¬ ì œëª©]
{title}

[ê¸°ì‚¬ ë³¸ë¬¸]
{content}

[ìš”ì•½ ìš”êµ¬ì‚¬í•­]
1. ì œëª©ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­
2. í•µì‹¬ ë‚´ìš©ì„ 1-2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½
3. ì„¸ë¶€ ë‚´ìš©ì„ 3-5ê°œ í•­ëª©ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì •ë¦¬
4. ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ì´ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰

[ì‘ë‹µ í˜•ì‹]
JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "title_korean": "ì œëª© í•œêµ­ì–´ ë²ˆì—­",
  "summary_oneline": "í•µì‹¬ ë‚´ìš© 1-2ë¬¸ì¥ ìš”ì•½",
  "details": [
    "ì„¸ë¶€ ë‚´ìš© 1",
    "ì„¸ë¶€ ë‚´ìš© 2", 
    "ì„¸ë¶€ ë‚´ìš© 3"
  ]
}}

[ì˜ˆì‹œ]
{{
  "title_korean": "VW, BEV (ID. ì‹œë¦¬ì¦ˆ) ê°€ê²© ë™ê²°",
  "summary_oneline": "í­ìŠ¤ë°”ê²ì´ '26ë…„ì‹ë¶€í„° ID. ì‹œë¦¬ì¦ˆ, T-Roc ë“± BEVëŠ” ì—°ë¡€ ê°€ê²© ì¸ìƒì—ì„œ ì œì™¸, ICEëŠ” í‰ê·  1.5% ì¸ìƒ ì˜ˆì •",
  "details": [
    "ì‘ë…„ '25ë…„ì‹ ì¶œì‹œ ëª¨ë¸ì— ëŒ€í•œ ê°€ê²© ì—°ë¡€ ì¸ìƒ ì‹œ ICEê°€ê²© 2.1%ì—ì„œ 3.2%ë¡œ ì¸ìƒ ë° BEV ê°€ê²©ì€ ë™ê²°í•œ ê²ƒê³¼ ìœ ì‚¬ í–‰ë³´",
    "ì˜¬í•´ ë…ì¼ ë‚´ VW íŒë§¤ ì°¨ì¢… 5ëŒ€ ì¤‘ 1ëŒ€ëŠ” BEV ëª¨ë¸ì¸ ì  ë“± ì‹œì¥ ì¹¨íˆ¬ìœ¨ ê³ ë ¤í•˜ì—¬ BEV ê°€ê²© ê²½ìŸë ¥ ìœ ì§€ ë° ì†Œë¹„ì ë¶€ë‹´ ì ˆê° ëª©í‘œ",
    "ë‹¤ë§Œ ë™ê²°í•œ BEV ê°€ê²©ì˜ ê²½ìš° ì •ê°€ì—ë§Œ í•´ë‹¹í•˜ë©° ì™¸ê´€ ì»¬ëŸ¬, ìŠ¤í¬ì¸ Â·ë””ìì¸ íŒ¨í‚¤ì§€ ë“± ê°œë³„ ì¶”ê°€ ì˜µì…˜ì˜ ê°€ê²©ì€ ìƒí–¥ ì˜ˆì •",
    "ì²« ì°¨ëŸ‰ LS6ì— 8ì›” 15ì¼ ì‚¬ì „ íŒë§¤ ì‹œì‘, í”Œë˜ê·¸ì‹­ SUV LS9ëŠ” 2025ë…„ 4ë¶„ê¸° ê³µì‹ ì¶œì‹œ ì˜ˆì •"
  ]
}}

[ì¤‘ìš”] ë°˜ë“œì‹œ ì™„ì „í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ ê²ƒ.
[ì¤‘ìš”] ëª¨ë“  ë¬¸ì¥ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•  ê²ƒ.  
[ì¤‘ìš”] ë¬¸ì²´ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë³´ê³ ì„œ ìš”ì•½ì²´(ì˜ˆ: ~í•¨, ~ì„, ~ìŒ)ë¡œ ì‘ì„±í•  ê²ƒ.  
"""
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ìˆ˜ì •ëœ ë°©ì‹)
        try:
            llm = ChatOpenAI(
                #model="openai.gpt-4.1-2025-04-14",  #pwc
                model="gpt-4.1",
                temperature=0.3,
                request_timeout=30,
                openai_api_key=os.getenv("OPENAI_API_KEY"),
                openai_api_base=os.getenv("OPENAI_BASE_URL")
            )
            
            # AI ìš”ì•½ ìƒì„±
            messages = [
                SystemMessage(content="ë‹¹ì‹ ì€ ìë™ì°¨ ì‚°ì—… ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ í˜„ëŒ€ìë™ì°¨ ì—°êµ¬ê°œë°œ ê´€ì ì—ì„œ ìš”ì•½í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."),
                HumanMessage(content=summary_prompt)
            ]
            
            response = llm.invoke(messages)
            # JSON ì‘ë‹µ íŒŒì‹± ë° í¬ë§·íŒ…
            summary_content = response.content
            return _format_json_summary(summary_content)
            
        except Exception as e:
            print(f"ChatOpenAI ì´ˆê¸°í™” ë˜ëŠ” í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            # ê°„ë‹¨í•œ OpenAI í´ë¼ì´ì–¸íŠ¸ë¡œ ëŒ€ì²´
            try:
                from openai import OpenAI
                client = OpenAI(
                    api_key=os.getenv("OPENAI_API_KEY"),
                    base_url=os.getenv("OPENAI_BASE_URL")
                )
                
                # ì§ì ‘ API í˜¸ì¶œ
                response = client.chat.completions.create(
                    model="gpt-4.1",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ìë™ì°¨ ì‚°ì—… ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ í˜„ëŒ€ìë™ì°¨ ì—°êµ¬ê°œë°œ ê´€ì ì—ì„œ ìš”ì•½í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."},
                        {"role": "user", "content": summary_prompt}
                    ],
                    temperature=0.3,
                    max_tokens=1000
                )
                # JSON ì‘ë‹µ íŒŒì‹± ë° í¬ë§·íŒ…
                summary_content = response.choices[0].message.content
                return _format_json_summary(summary_content)
                
            except Exception as fallback_error:
                print(f"OpenAI ì§ì ‘ í˜¸ì¶œë„ ì‹¤íŒ¨: {fallback_error}")
                return f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(fallback_error)}"
        
    except Exception as e:
        print(f"AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        return f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}"

def _clean_html_tags(text: str) -> str:
    """HTML íƒœê·¸ë¥¼ ì œê±°í•˜ê³  ê¹”ë”í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    import re
    
    if not text:
        return ""
    
    # HTML íƒœê·¸ ì œê±°
    text = re.sub(r'<[^>]+>', '', text)
    
    # HTML ì—”í‹°í‹° ë³€í™˜
    html_entities = {
        '&amp;': '&',
        '&lt;': '<',
        '&gt;': '>',
        '&quot;': '"',
        '&#39;': "'",
        '&nbsp;': ' '
    }
    
    for entity, char in html_entities.items():
        text = text.replace(entity, char)
    
    # ì—°ì†ëœ ê³µë°±ê³¼ ì¤„ë°”ê¿ˆ ì •ë¦¬
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\n\s*\n', '\n\n', text)
    
    return text.strip()

def _format_json_summary(json_response: str) -> str:
    """ìš”ì•½ JSON ì‘ë‹µì„ HTML í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    import json
    import re
    
    try:
        # JSON ì‘ë‹µì—ì„œ ì½”ë“œ ë¸”ë¡ ì œê±°
        json_text = json_response.strip()
        if json_text.startswith("```json"):
            json_text = json_text[7:]
        if json_text.startswith("```"):
            json_text = "\n".join(json_text.split("\n")[1:])
        if json_text.endswith("```"):
            json_text = "\n".join(json_text.split("\n")[:-1])
        
        json_text = json_text.strip()
        
        # JSON íŒŒì‹±
        summary_data = json.loads(json_text)
        
        # HTML í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        title_korean = summary_data.get('title_korean', 'ì œëª© ì—†ìŒ')
        summary_oneline = summary_data.get('summary_oneline', 'ìš”ì•½ ì—†ìŒ')
        details = summary_data.get('details', [])
        
        # HTML í¬ë§·íŒ…
        html_content = f"""
<div style="margin-bottom: 15px;">
    <h4 style="color: #333; margin-bottom: 10px; font-size: 1.2em; font-weight: bold;">{title_korean}</h4>
    <div style="background-color: #f0f8ff; padding: 12px; border-radius: 6px; margin-bottom: 12px; border-left: 3px solid #0077b6;">
        <strong>*</strong> {summary_oneline}
    </div>
</div>
"""
        
        if details:
            html_content += "<div style='margin-top: 8px;'>\n"
            for detail in details:
                html_content += f"<div style='margin-bottom: 6px; line-height: 1.4;'>- {detail}</div>\n"
            html_content += "</div>"
        
        return html_content
        
    except json.JSONDecodeError as e:
        print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        print(f"ì›ë³¸ ì‘ë‹µ: {json_response}")
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
        return f"<div style='color: #666;'>ìš”ì•½ íŒŒì‹± ì˜¤ë¥˜:<br>{json_response}</div>"
    except Exception as e:
        print(f"ìš”ì•½ í¬ë§·íŒ… ì˜¤ë¥˜: {e}")
        return f"<div style='color: #666;'>ìš”ì•½ í¬ë§·íŒ… ì˜¤ë¥˜:<br>{json_response}</div>"

# 1ë‹¨ê³„: ë‰´ìŠ¤ ì œì™¸ íŒë‹¨
def filter_excluded_news(state: AgentState) -> AgentState:
    """ë‰´ìŠ¤ë¥¼ ì œì™¸/ë³´ë¥˜/ìœ ì§€ë¡œ ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        system_prompt = state.get("system_prompt_1", "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ì˜ ì¤‘ìš”ì„±ì„ íŒë‹¨í•˜ì—¬ ì œì™¸/ë³´ë¥˜/ìœ ì§€ë¡œ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. íŠ¹íˆ íšŒê³„ë²•ì¸ì˜ ê´€ì ì—ì„œ ì¤‘ìš”í•˜ì§€ ì•Šì€ ë‰´ìŠ¤(ì˜ˆ: ë‹¨ìˆœ í™ë³´, CSR í™œë™, ì´ë²¤íŠ¸ ë“±)ë¥¼ ì‹ë³„í•˜ê³ , íšŒê³„ ê°ë¦¬ë‚˜ ì¬ë¬´ ê´€ë ¨ ì´ìŠˆëŠ” ë°˜ë“œì‹œ ìœ ì§€í•˜ë„ë¡ í•©ë‹ˆë‹¤.")
        
        # ë‰´ìŠ¤ ë°ì´í„° ì¤€ë¹„
        news_data = state.get("news_data", [])
        if not news_data:
            st.error("ë¶„ì„í•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return state
            
        # ë‰´ìŠ¤ ëª©ë¡ ë¬¸ìì—´ ìƒì„± - ì›ë˜ ì¸ë±ìŠ¤ ì‚¬ìš©
        news_list = ""
        for news in news_data:
            press = news.get('press', 'ì•Œ ìˆ˜ ì—†ìŒ')
            original_index = news.get('original_index')
            news_list += f"{original_index}. {news['content']} ({press})\n"
            
        # ì œì™¸ íŒë‹¨ í”„ë¡¬í”„íŠ¸
        exclusion_prompt = f"""ì•„ë˜ ë‰´ìŠ¤ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬ ì œì™¸/ë³´ë¥˜/ìœ ì§€ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.
ê° ë‰´ìŠ¤ì˜ ë²ˆí˜¸ëŠ” ê³ ìœ  ì‹ë³„ìì´ë¯€ë¡œ ë³€ê²½í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì‘ë‹µì— ì‚¬ìš©í•´ì£¼ì„¸ìš”.

[ë‰´ìŠ¤ ëª©ë¡]
{news_list}

[ì œì™¸ ê¸°ì¤€]
{state.get("exclusion_criteria", "")}

[ì‘ë‹µ ìš”êµ¬ì‚¬í•­]
1. ì œì™¸/ë³´ë¥˜/ìœ ì§€ ì‚¬ìœ ëŠ” ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì‘ì„±
2. ê° ì¹´í…Œê³ ë¦¬ë³„ ìµœëŒ€ 20ê°œê¹Œì§€ë§Œ í¬í•¨
3. ì‘ë‹µì€ ì™„ì „í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•¨

ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "excluded": [
    {{
      "index": 1,
      "title": "ë‰´ìŠ¤ ì œëª©",
      "reason": "ì œì™¸ ì‚¬ìœ "
    }}
  ],
  "borderline": [
    {{
      "index": 2,
      "title": "ë‰´ìŠ¤ ì œëª©",
      "reason": "ë³´ë¥˜ ì‚¬ìœ "
    }}
  ],
  "retained": [
    {{
      "index": 3,
      "title": "ë‰´ìŠ¤ ì œëª©",
      "reason": "ìœ ì§€ ì‚¬ìœ "
    }}
  ]
}}"""

        # ìµœëŒ€ 3ë²ˆê¹Œì§€ ì‹œë„
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # LLM í˜¸ì¶œ (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
                result = call_llm(state, system_prompt, exclusion_prompt, stage=1)
                
                # JSON íŒŒì‹± (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
                classification = parse_json_response(result)
                
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                if not all(key in classification for key in ["excluded", "borderline", "retained"]):
                    raise ValueError("í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹œ ì›ë˜ ì¸ë±ìŠ¤ ìœ ì§€
                for category in ["excluded", "borderline", "retained"]:
                    for item in classification.get(category, []):
                        original_index = item['index']
                        item['original_index'] = original_index
                
                state["excluded_news"] = classification.get("excluded", [])
                state["borderline_news"] = classification.get("borderline", [])
                state["retained_news"] = classification.get("retained", [])
                
                print("\n[ë¶„ë¥˜ ê²°ê³¼]")
                print(f"ì œì™¸: {len(state['excluded_news'])}ê°œ")
                print(f"ë³´ë¥˜: {len(state['borderline_news'])}ê°œ")
                print(f"ìœ ì§€: {len(state['retained_news'])}ê°œ")
                
                # ê° ì¹´í…Œê³ ë¦¬ë³„ ìƒ˜í”Œ ì¶œë ¥
                if state['excluded_news']:
                    print(f"\nì œì™¸ëœ ë‰´ìŠ¤ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
                    for i, news in enumerate(state['excluded_news'][:3], 1):
                        print(f"  {i}. {news.get('title', 'ì œëª© ì—†ìŒ')} - {news.get('reason', 'ì´ìœ  ì—†ìŒ')}")
                
                if state['retained_news']:
                    print(f"\nìœ ì§€ëœ ë‰´ìŠ¤ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
                    for i, news in enumerate(state['retained_news'][:3], 1):
                        print(f"  {i}. {news.get('title', 'ì œëª© ì—†ìŒ')} - {news.get('reason', 'ì´ìœ  ì—†ìŒ')}")
                
                if state['borderline_news']:
                    print(f"\në³´ë¥˜ëœ ë‰´ìŠ¤ ìƒ˜í”Œ:")
                    for i, news in enumerate(state['borderline_news'], 1):
                        print(f"  {i}. {news.get('title', 'ì œëª© ì—†ìŒ')} - {news.get('reason', 'ì´ìœ  ì—†ìŒ')}")
                
                # ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±ë˜ë©´ ë£¨í”„ ì¢…ë£Œ
                break
                
            except (json.JSONDecodeError, ValueError) as e:
                print(f"\níŒŒì‹± ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(e)}")
                if attempt == max_retries - 1:  # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œë„ ì‹¤íŒ¨
                    st.error(f"ë¶„ë¥˜ ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    return state
                # ë‹¤ìŒ ì‹œë„ë¥¼ ìœ„í•´ ì ì‹œ ëŒ€ê¸°
                time.sleep(1)

        return state

    except Exception as e:
        st.error(f"ë‰´ìŠ¤ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return state

# 2ë‹¨ê³„: ë‰´ìŠ¤ ê·¸ë£¹í•‘ + ëŒ€í‘œ ê¸°ì‚¬ ì„ íƒ
def group_and_select_news(state: AgentState) -> AgentState:
    try:
        # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        print("\n=== ê·¸ë£¹í•‘ ì „ ì¸ë±ìŠ¤ ì •ë³´ ===")
        print(f"ë³´ë¥˜ ë‰´ìŠ¤ ì¸ë±ìŠ¤: {[news['index'] for news in state['borderline_news']]}")
        print(f"ìœ ì§€ ë‰´ìŠ¤ ì¸ë±ìŠ¤: {[news['index'] for news in state['retained_news']]}")

        # ìœ ì§€ ë° ë³´ë¥˜ ë‰´ìŠ¤ í•©ì¹˜ê¸°
        retained_indices = [news["index"] for news in state["retained_news"]]
        borderline_indices = [news["index"] for news in state["borderline_news"]]
        target_indices = retained_indices + borderline_indices
        
        print(f"ëŒ€ìƒ ë‰´ìŠ¤ ì¸ë±ìŠ¤: {target_indices}")
        
        # ëŒ€ìƒ ë‰´ìŠ¤ í•„í„°ë§ (ì›ë˜ ì¸ë±ìŠ¤ ë§¤í•‘)
        target_news = []
        for news in state["news_data"]:
            original_index = news.get("original_index")
            if original_index in target_indices:
                print(f"ë§¤ì¹­ëœ ë‰´ìŠ¤: index={original_index}, title={news['content']}")
                news["current_index"] = original_index  # current_indexì— original_index ì €ì¥
                target_news.append(news)
        
        print(f"í•„í„°ë§ëœ ëŒ€ìƒ ë‰´ìŠ¤ ìˆ˜: {len(target_news)}")
        
        if not target_news:
            print("í•„í„°ë§ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return state

        # ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (current_index ì‚¬ìš©)
        news_text = "\n\n".join([
            f"ì¸ë±ìŠ¤: {news['current_index']}\nì œëª©: {news['content']}\nì–¸ë¡ ì‚¬: {news.get('press', 'ì•Œ ìˆ˜ ì—†ìŒ')}\në°œí–‰ì¼: {news.get('date', 'ì•Œ ìˆ˜ ì—†ìŒ')}"
            for news in target_news
        ])

        # ê·¸ë£¹í•‘ í”„ë¡¬í”„íŠ¸
        system_prompt = state.get("system_prompt_2", "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìœ ì‚¬í•œ ë‰´ìŠ¤ë¥¼ ê·¸ë£¹í™”í•˜ê³  ëŒ€í‘œì„±ì„ ê°–ì¶˜ ê¸°ì‚¬ë¥¼ ì„ íƒí•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ê°™ì€ ì‚¬ì•ˆì— ëŒ€í•´ ìˆ«ì, ê¸°ì—… ,ê³„ì—´ì‚¬, ë§¥ë½, ì£¼ìš” í‚¤ì›Œë“œ ë“±ì´ ìœ ì‚¬í•˜ë©´ ì¤‘ë³µìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤. ì–¸ë¡ ì‚¬ì˜ ì‹ ë¢°ë„ì™€ ê¸°ì‚¬ì˜ ìƒì„¸ë„ë¥¼ ê³ ë ¤í•˜ì—¬ ëŒ€í‘œ ê¸°ì‚¬ë¥¼ ì„ ì •í•©ë‹ˆë‹¤.")
        
        grouping_prompt = f"""ìœ ì‚¬í•œ ë‰´ìŠ¤ë¼ë¦¬ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ê³ , ê° ê·¸ë£¹ì—ì„œ ê°€ì¥ ëŒ€í‘œì„± ìˆëŠ” ë‰´ìŠ¤ 1ê±´ë§Œ ì„ íƒí•´ ì£¼ì„¸ìš”.
ì£¼ì–´ì§„ ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ ì •í™•íˆ ì‚¬ìš©í•´ì£¼ì„¸ìš”. ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ ì„ì˜ë¡œ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”.

[ë‰´ìŠ¤ ëª©ë¡]
{news_text}

[ì¤‘ë³µ ì²˜ë¦¬ ê¸°ì¤€]
{state.get("duplicate_handling", "")}

ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "groups": [
    {{
      "indices": [2, 4],
      "selected_index": 2,
      "reason": "ë™ì¼í•œ íšŒì›ê¶Œ ê´€ë ¨ ë³´ë„ì´ë©°, 2ë²ˆì´ ë” ìì„¸í•˜ê³  ì–¸ë¡ ì‚¬ ìš°ì„ ìˆœìœ„ê°€ ë†’ìŒ"
    }},
    {{
      "indices": [5],
      "selected_index": 5,
      "reason": "ë‹¨ë… ê¸°ì‚¬"
    }}
  ]
}}"""

        try:
            # LLM í˜¸ì¶œ (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
            result = call_llm(state, system_prompt, grouping_prompt, stage=2)
            
            # JSON íŒŒì‹± (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
            grouping = parse_json_response(result)
            grouped_news = grouping.get("groups", [])
            
            # ê·¸ë£¹í•‘ëœ ë‰´ìŠ¤ì˜ ì¸ë±ìŠ¤ë“¤ì„ ëª¨ë‘ ìˆ˜ì§‘
            grouped_indices = set()
            for group in grouped_news:
                grouped_indices.update(group.get("indices", []))
            
            # ê·¸ë£¹í•‘ë˜ì§€ ì•Šì€ ë‰´ìŠ¤ë“¤ì„ ì°¾ì•„ì„œ ê°ê° ë‹¨ì¼ ê·¸ë£¹ìœ¼ë¡œ ì¶”ê°€
            current_indices = set(news["current_index"] for news in target_news)
            ungrouped_indices = current_indices - grouped_indices
            
            # ë¯¸ê·¸ë£¹ ë‰´ìŠ¤ë“¤ì„ ê°ê° ë‹¨ì¼ ê·¸ë£¹ìœ¼ë¡œ ì¶”ê°€
            for idx in ungrouped_indices:
                new_group = {
                    "indices": [idx],
                    "selected_index": idx,
                    "reason": "ê°œë³„ ë‰´ìŠ¤ë¡œ ì²˜ë¦¬"
                }
                grouped_news.append(new_group)
            
            # ê·¸ë£¹í•‘ ê²°ê³¼ ì €ì¥
            state["grouped_news"] = grouped_news
            
            # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
            print("\n=== ê·¸ë£¹í•‘ ê²°ê³¼ ===")
            for group in grouped_news:
                print(f"ê·¸ë£¹: {group['indices']}, ì„ íƒëœ ì¸ë±ìŠ¤: {group['selected_index']}")
            
            return state

        except json.JSONDecodeError as e:
            st.error(f"ê·¸ë£¹í•‘ ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return state

    except Exception as e:
        st.error(f"ë‰´ìŠ¤ ê·¸ë£¹í•‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return state

# 3ë‹¨ê³„: ì¤‘ìš”ë„ í‰ê°€ + ìµœì¢… ì„ ì •
def evaluate_importance(state: AgentState) -> AgentState:
    try:
        # ì„ íƒëœ ë‰´ìŠ¤ ì¶”ì¶œ
        selected_news = []
        index_map = {}  # ë¦¬ìŠ¤íŠ¸ ì¸ë±ìŠ¤ì™€ ì›ë˜ ì¸ë±ìŠ¤ ê°„ì˜ ë§¤í•‘
        
        # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        print("\n=== ì¤‘ìš”ë„ í‰ê°€ ì‹œì‘ ===")
        print(f"ê·¸ë£¹ ìˆ˜: {len(state['grouped_news'])}")
        
        # ê° ê·¸ë£¹ì—ì„œ ì„ íƒëœ ë‰´ìŠ¤ ì°¾ê¸°
        for i, group in enumerate(state["grouped_news"], 1):
            selected_index = group["selected_index"]
            
            # ì›ë˜ ë‰´ìŠ¤ ë°ì´í„°ì—ì„œ selected_indexì™€ ì¼ì¹˜í•˜ëŠ” ë‰´ìŠ¤ ì°¾ê¸°
            selected_article = next(
                (news for news in state["news_data"] 
                 if news.get("original_index") == selected_index),
                None
            )
            
            if selected_article:
                print(f"ê·¸ë£¹ {i}, ì„ íƒëœ ì¸ë±ìŠ¤ {selected_index}: ì œëª© = {selected_article['content']}")
                # ë¦¬ìŠ¤íŠ¸ ì¸ë±ìŠ¤ë¥¼ ië¡œ, ì›ë˜ ì¸ë±ìŠ¤ë¥¼ selected_indexë¡œ ë§¤í•‘
                index_map[i] = selected_index
                selected_article["list_index"] = i
                selected_article["group_info"] = group
                selected_news.append(selected_article)
            else:
                print(f"ê·¸ë£¹ {i}, ì„ íƒëœ ì¸ë±ìŠ¤ {selected_index}: í•´ë‹¹ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
        if not selected_news:
            print("ì„ íƒëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return state

        # ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (list_index ì‚¬ìš©)
        news_text = "\n\n".join([
            f"ì¸ë±ìŠ¤: {news['list_index']}\nì œëª©: {news['content']}\nì–¸ë¡ ì‚¬: {news.get('press', 'ì•Œ ìˆ˜ ì—†ìŒ')}\në°œí–‰ì¼: {news.get('date', 'ì•Œ ìˆ˜ ì—†ìŒ')}"
            for news in selected_news
        ])

        # ì¤‘ìš”ë„ í‰ê°€ í”„ë¡¬í”„íŠ¸
        system_prompt = state.get("system_prompt_3", "ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ì˜ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë‰´ìŠ¤ì˜ ì¤‘ìš”ë„ë¥¼ í‰ê°€í•˜ê³  ìµœì¢… ì„ ì •í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. íŠ¹íˆ íšŒê³„ ê°ë¦¬, ì¬ë¬´ì œí‘œ, ê²½ì˜ê¶Œ ë³€ë™, ì£¼ìš” ê³„ì•½, ë²•ì  ë¶„ìŸ ë“± íšŒê³„ë²•ì¸ì˜ ê´€ì ì—ì„œ ì¤‘ìš”í•œ ì´ìŠˆë¥¼ ì‹ë³„í•˜ê³ , ê·¸ ì¤‘ìš”ë„ë¥¼ 'ìƒ' ë˜ëŠ” 'ì¤‘'ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤. ë˜í•œ ê° ë‰´ìŠ¤ì˜ í•µì‹¬ í‚¤ì›Œë“œì™€ ê´€ë ¨ ê³„ì—´ì‚¬ë¥¼ ì‹ë³„í•˜ì—¬ ë³´ê³ í•©ë‹ˆë‹¤.")
        
        evaluation_prompt = f"""ì•„ë˜ ê¸°ì‚¬ë“¤ì— ëŒ€í•´ ì¤‘ìš”ë„ë¥¼ í‰ê°€í•˜ê³ , ëª¨ë“  ë‰´ìŠ¤ì— ëŒ€í•´ í‰ê°€ ê²°ê³¼ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.
ì¤‘ìš”ë„ 'ìƒ' ë˜ëŠ” 'ì¤‘'ì¸ ë‰´ìŠ¤ëŠ” ìµœì¢… ì„ ì •í•˜ê³ , 'í•˜'ì¸ ë‰´ìŠ¤ëŠ” ì„ ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

[ë‰´ìŠ¤ ëª©ë¡]
{news_text}

[ì„ íƒ ê¸°ì¤€]
{state.get("selection_criteria", "")}

[ì‘ë‹µ ìš”êµ¬ì‚¬í•­]
1. ì¤‘ìš”ë„ëŠ” "ìƒ", "ì¤‘", "í•˜" ì¤‘ í•˜ë‚˜ë¡œ í‰ê°€
2. ë¯¸ì„ ì • ì‚¬ìœ ëŠ” ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì‘ì„±
3. ì‘ë‹µì€ ì™„ì „í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•¨

ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "final_selection": [
        {{
            "index": 2,
            "title": "ë‰´ìŠ¤ ì œëª©",
            "importance": "ìƒ",
            "reason": "ì„ ì • ì‚¬ìœ ",
            "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
            "affiliates": ["ê³„ì—´ì‚¬1", "ê³„ì—´ì‚¬2"],
            "press": "ì–¸ë¡ ì‚¬ëª…",
            "date": "ë°œí–‰ì¼"
        }}
  ],
  "not_selected": [
    {{
      "index": 3,
      "title": "ë‰´ìŠ¤ ì œëª©",
      "importance": "í•˜",
      "reason": "ë¯¸ì„ ì • ì‚¬ìœ "
    }}
  ]
}}"""

        # ìµœëŒ€ 3ë²ˆê¹Œì§€ ì‹œë„
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # LLM í˜¸ì¶œ (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
                result = call_llm(state, system_prompt, evaluation_prompt, stage=3)
                
                # JSON íŒŒì‹± (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
                evaluation = parse_json_response(result)
                
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                if not all(key in evaluation for key in ["final_selection", "not_selected"]):
                    raise ValueError("í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ìµœì¢… ì„ ì •ëœ ë‰´ìŠ¤ ì²˜ë¦¬
                for news in evaluation["final_selection"]:
                    list_index = news["index"]
                    if list_index in index_map:
                        original_index = index_map[list_index]
                        original_news = next(
                            (n for n in selected_news if n["list_index"] == list_index),
                            None
                        )
                        if original_news:
                            # ì›ë³¸ ë°ì´í„°ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                            news.update({
                                "url": original_news.get("url", ""),
                                "press": original_news.get("press", ""),  # LLMì´ ì œê³µí•œ press ëŒ€ì‹  ì›ë³¸ press ì‚¬ìš©
                                "date": original_news.get("date", ""),
                                "original_index": original_index,
                                "group_info": original_news["group_info"]
                            })
                            print(f"ìµœì¢… ì„ ì • ë‰´ìŠ¤: ì¸ë±ìŠ¤={original_index}, ì œëª©={news['title']}")

                # ë¯¸ì„ ì • ë‰´ìŠ¤ë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
                for news in evaluation["not_selected"]:
                    list_index = news["index"]
                    if list_index in index_map:
                        original_index = index_map[list_index]
                        original_news = next(
                            (n for n in selected_news if n["list_index"] == list_index),
                            None
                        )
                        if original_news:
                            news.update({
                                "url": original_news.get("url", ""),
                                "press": original_news.get("press", ""),  # LLMì´ ì œê³µí•œ press ëŒ€ì‹  ì›ë³¸ press ì‚¬ìš©
                                "date": original_news.get("date", ""),
                                "original_index": original_index,
                                "group_info": original_news["group_info"]
                            })
                            print(f"ë¯¸ì„ ì • ë‰´ìŠ¤: ì¸ë±ìŠ¤={original_index}, ì œëª©={news['title']}")
                
                state["final_selection"] = evaluation.get("final_selection", [])
                state["not_selected_news"] = evaluation.get("not_selected", [])
                
                print(f"ìµœì¢… ì„ ì • ë‰´ìŠ¤ ìˆ˜: {len(state['final_selection'])}")
                print(f"ë¯¸ì„ ì • ë‰´ìŠ¤ ìˆ˜: {len(state['not_selected_news'])}")
                
                # ìµœì¢… ì„ ì •ëœ ë‰´ìŠ¤ ìƒì„¸ ì •ë³´ ì¶œë ¥
                if state['final_selection']:
                    print(f"\n=== ìµœì¢… ì„ ì •ëœ ë‰´ìŠ¤ ===")
                    for i, news in enumerate(state['final_selection'], 1):
                        print(f"{i}. {news.get('title', 'ì œëª© ì—†ìŒ')}")
                        print(f"   ì¤‘ìš”ë„: {news.get('importance', 'ì—†ìŒ')}")
                        print(f"   ì–¸ë¡ ì‚¬: {news.get('press', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                        print(f"   ì„ ì • ì‚¬ìœ : {news.get('reason', 'ì´ìœ  ì—†ìŒ')}")
                        print("---")
                else:
                    print("\nâš ï¸ ìµœì¢… ì„ ì •ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
                    
                # ë¯¸ì„ ì • ë‰´ìŠ¤ ìƒ˜í”Œ ì¶œë ¥
                if state['not_selected_news']:
                    print(f"\në¯¸ì„ ì • ë‰´ìŠ¤ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
                    for i, news in enumerate(state['not_selected_news'][:3], 1):
                        print(f"  {i}. {news.get('title', 'ì œëª© ì—†ìŒ')} - {news.get('reason', 'ì´ìœ  ì—†ìŒ')}")
                
                return state

            except (json.JSONDecodeError, ValueError) as e:
                print(f"\níŒŒì‹± ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(e)}")
                if attempt == max_retries - 1:  # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œë„ ì‹¤íŒ¨
                    st.error(f"ì¤‘ìš”ë„ í‰ê°€ ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    return state
                # ë‹¤ìŒ ì‹œë„ë¥¼ ìœ„í•´ ì ì‹œ ëŒ€ê¸°
                time.sleep(1)

        return state

    except Exception as e:
        st.error(f"ì¤‘ìš”ë„ í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return state

# ë…¸ë“œ ì •ì˜
def get_nodes():
    return {
        "collect_news": collect_news,
        "filter_valid_press": filter_valid_press,
        "filter_excluded_news": filter_excluded_news,
        "group_and_select_news": group_and_select_news,
        "evaluate_importance": evaluate_importance
    }

# ì—ì§€ ì •ì˜
def get_edges():
    return [
        ("collect_news", "filter_valid_press"),
        ("filter_valid_press", "filter_excluded_news"),
        ("filter_excluded_news", "group_and_select_news"),
        ("group_and_select_news", "evaluate_importance"),
        ("evaluate_importance", END)
    ]

# ë‰´ìŠ¤ ì¶œë ¥ í•¨ìˆ˜
def print_news(news_list, title):
    print(f"\n=== {title} ===")
    for i, news in enumerate(news_list):
        print(f"\n[{i+1}] ì œëª©: {news['content']}")
        print(f"    URL: {news['url']}")

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    # ë…¸ë“œ ë° ì—ì§€ ê°€ì ¸ì˜¤ê¸°
    nodes = get_nodes()
    edges = get_edges()
    
    # ê·¸ë˜í”„ ìƒì„±
    builder = StateGraph(AgentState)
    
    # ë…¸ë“œ ì¶”ê°€
    for node_name, node_fn in nodes.items():
        builder.add_node(node_name, node_fn)
    
    # ì—ì§€ ì¶”ê°€
    for start, end in edges:
        builder.add_edge(start, end)
    
    # ì‹œì‘ì  ì„¤ì •
    builder.set_entry_point("collect_news")
    
    # ê·¸ë˜í”„ ì»´íŒŒì¼
    graph = builder.compile()
    
    # ì‹¤í–‰
    # ë¹ˆ ì´ˆê¸° ìƒíƒœë¡œ ì‹œì‘
    result = graph.invoke({
        "news_data": [],
        "filtered_news": [],
        "analysis": "",
        "keyword": "ì‚¼ì„±ì „ì",
        "system_prompt": "",
        "user_prompt": "",
        "excluded_news": [],
        "borderline_news": [],
        "retained_news": [],
        "grouped_news": [],
        "final_selection": [],
        "system_prompt_1": "",
        "user_prompt_1": "",
        "llm_response_1": "",
        "system_prompt_2": "",
        "user_prompt_2": "",
        "llm_response_2": "",
        "system_prompt_3": "",
        "user_prompt_3": "",
        "llm_response_3": "",
        "not_selected_news": [],
        "original_news_data": [],
        "start_datetime": datetime.now(),
        "end_datetime": datetime.now() + timedelta(days=7)
    })
    
    # ì „ì²´ ë‰´ìŠ¤ ëª©ë¡ ì¶œë ¥
    print_news(result["original_news_data"], "ì „ì²´ ë‰´ìŠ¤ (50ê°œ)")
    
    # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    print("\n\n=== íšŒê³„ë²•ì¸ ê´€ì ì˜ ë¶„ì„ ê²°ê³¼ ===")
    print(result["analysis"])
    
    # ì„ ë³„ëœ ë‰´ìŠ¤ ì¶œë ¥
    print_news(result["filtered_news"], "íšŒê³„ë²•ì¸ ê´€ì ì˜ ì£¼ìš” ë‰´ìŠ¤")

if __name__ == "__main__":
    main()
