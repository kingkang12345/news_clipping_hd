import streamlit as st
import re


# âœ… ë¬´ì¡°ê±´ ì²« Streamlit ëª…ë ¹ì–´
st.set_page_config(
    page_title="PwC ë‰´ìŠ¤ ë¶„ì„ê¸°",
    page_icon="ğŸ“Š",
    layout="wide",
)



from datetime import datetime, timedelta, timezone
import os
from PIL import Image
import docx
from docx.shared import Pt, RGBColor, Inches
import io
from urllib.parse import urlparse
from googlenews import GoogleNews
from news_ai import (
    collect_news,
    filter_valid_press,
    filter_excluded_news,
    group_and_select_news,
    evaluate_importance,
    summarize_selected_articles,
    _generate_article_summary,
)

# Import centralized configuration
from config import (
    COMPANY_CATEGORIES,
    COMPANY_KEYWORD_MAP,
    COMPANY_STRUCTURE_NEW,  # ìƒˆë¡œìš´ êµ¬ì¡° ì¶”ê°€
    COMPANY_STRUCTURE_ENGLISH,  # ì˜ì–´ í‚¤ì›Œë“œ êµ¬ì¡° ì¶”ê°€
    ANALYSIS_SCOPE_CRITERIA,  # ë¶„ì„ ë²”ìœ„ë³„ íŠ¹í™” ê¸°ì¤€ ì¶”ê°€
    ANALYSIS_SCOPE_SYSTEM_PROMPTS,  # ë¶„ì„ ë²”ìœ„ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    TRUSTED_PRESS_ALIASES,
    ADDITIONAL_PRESS_ALIASES,
    SYSTEM_PROMPT_1,
    SYSTEM_PROMPT_2,
    SYSTEM_PROMPT_3,
    EXCLUSION_CRITERIA,
    DUPLICATE_HANDLING,
    SELECTION_CRITERIA, 
    GPT_MODELS,
    DEFAULT_GPT_MODEL,
    # ìƒˆë¡œ ì¶”ê°€ë˜ëŠ” íšŒì‚¬ë³„ ê¸°ì¤€ë“¤
    COMPANY_ADDITIONAL_EXCLUSION_CRITERIA,
    COMPANY_ADDITIONAL_DUPLICATE_HANDLING,
    COMPANY_ADDITIONAL_SELECTION_CRITERIA
)

# í•œêµ­ ì‹œê°„ëŒ€(KST) ì •ì˜
KST = timezone(timedelta(hours=9))


def _clean_html_for_display(text: str) -> str:
    """HTML íƒœê·¸ë¥¼ ì™„ì „íˆ ì œê±°í•˜ê³  Streamlit í‘œì‹œìš©ìœ¼ë¡œ ì •ë¦¬"""
    import re
    
    if not text:
        return ""
    
    # ëª¨ë“  HTML íƒœê·¸ ì™„ì „ ì œê±° (ë” ê°•ë ¥í•œ ì •ê·œì‹)
    text = re.sub(r'<[^<>]*>', '', text)
    text = re.sub(r'<[^<>]*', '', text)  # ë‹«íˆì§€ ì•Šì€ íƒœê·¸ë„ ì œê±°
    text = re.sub(r'[^<>]*>', '', text)  # ì—¬ëŠ” íƒœê·¸ê°€ ì—†ëŠ” ë‹«ëŠ” íƒœê·¸ë„ ì œê±°
    
    # HTML ì—”í‹°í‹° ë³€í™˜
    html_entities = {
        '&amp;': '&',
        '&lt;': '<',
        '&gt;': '>',
        '&quot;': '"',
        '&#39;': "'",
        '&nbsp;': ' ',
        '&apos;': "'"
    }
    
    for entity, char in html_entities.items():
        text = text.replace(entity, char)
    
    # íŠ¹ì • HTML ê´€ë ¨ ë¬¸ìì—´ ì œê±°
    text = text.replace('</div>', '')
    text = text.replace('<div>', '')
    text = text.replace('<br>', '\n')
    text = text.replace('<br/>', '\n')
    text = text.replace('<br />', '\n')
    
    # ì—°ì†ëœ ê³µë°±ê³¼ ì¤„ë°”ê¿ˆ ì •ë¦¬
    text = re.sub(r'[ \t]+', ' ', text)
    text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
    
    return text.strip()

def _format_ai_summary_for_box(clean_summary, extraction_success):
    """AI ìš”ì•½ì„ íŒŒë€ìƒ‰ ë°•ìŠ¤ ì•ˆì— í¬í•¨ë˜ë„ë¡ HTML í¬ë§·íŒ… (JSON í˜•ì‹ ì§€ì›)"""
    if not clean_summary:
        return ""
    
    if not extraction_success:
        return f"""
            <div class="selection-reason">
                â€¢ âš ï¸ ì›ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: {clean_summary}
            </div>
        """
    
    # JSON í˜•ì‹ì˜ ìš”ì•½ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì´ë¯¸ _format_json_summaryì—ì„œ HTMLë¡œ ë³€í™˜ë¨)
    # ê¸°ì¡´ í…ìŠ¤íŠ¸ í˜•ì‹ì´ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
    if clean_summary.strip().startswith('<div'):
        # ì´ë¯¸ HTMLë¡œ í¬ë§·ëœ JSON ìš”ì•½
        return f"""
            {clean_summary}
        """
    
    return f"""
            {clean_summary}
    """

def format_date(date_str):
    """Format date to MM/DD format with proper timezone handling"""
    try:
        # Try YYYY-MM-DD format
        date_obj = datetime.strptime(date_str, '%Y-%m-%d')
        return date_obj.strftime('%m/%d')
    except Exception:
        try:
            # Try GMT format and convert to KST
            date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
            # Convert UTC to KST (add 9 hours)
            date_obj_kst = date_obj + timedelta(hours=9)
            return date_obj_kst.strftime('%m/%d')
        except Exception:
            try:
                # Try GMT format without timezone indicator
                date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S GMT')
                # Convert UTC to KST (add 9 hours)
                date_obj_kst = date_obj + timedelta(hours=9)
                return date_obj_kst.strftime('%m/%d')
            except Exception:
                # Return original if parsing fails
                return date_str if date_str else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'

# íšŒì‚¬ë³„ ì¶”ê°€ ê¸°ì¤€ì„ ì ìš©í•˜ëŠ” í•¨ìˆ˜ë“¤
def get_enhanced_exclusion_criteria(companies):
    """íšŒì‚¬ë³„ ì œì™¸ ê¸°ì¤€ì„ ì¶”ê°€í•œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜ (ì—¬ëŸ¬ íšŒì‚¬ ì§€ì›)"""
    base_criteria = EXCLUSION_CRITERIA
    
    # companiesê°€ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(companies, str):
        companies = [companies]
    
    # ì„ íƒëœ ëª¨ë“  íšŒì‚¬ì˜ ì¶”ê°€ ê¸°ì¤€ì„ í•©ì¹¨
    all_additional_criteria = ""
    for company in companies:
        additional_criteria = COMPANY_ADDITIONAL_EXCLUSION_CRITERIA.get(company, "")
        if additional_criteria:
            all_additional_criteria += additional_criteria
    
    return base_criteria + all_additional_criteria

def get_enhanced_duplicate_handling(companies):
    """íšŒì‚¬ë³„ ì¤‘ë³µ ì²˜ë¦¬ ê¸°ì¤€ì„ ì¶”ê°€í•œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜ (ì—¬ëŸ¬ íšŒì‚¬ ì§€ì›)"""
    base_criteria = DUPLICATE_HANDLING
    
    # companiesê°€ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(companies, str):
        companies = [companies]
    
    # ì„ íƒëœ ëª¨ë“  íšŒì‚¬ì˜ ì¶”ê°€ ê¸°ì¤€ì„ í•©ì¹¨
    all_additional_criteria = ""
    for company in companies:
        additional_criteria = COMPANY_ADDITIONAL_DUPLICATE_HANDLING.get(company, "")
        if additional_criteria:
            all_additional_criteria += additional_criteria
    
    return base_criteria + all_additional_criteria

def get_enhanced_selection_criteria(companies):
    """íšŒì‚¬ë³„ ì„ íƒ ê¸°ì¤€ì„ ì¶”ê°€í•œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜ (ì—¬ëŸ¬ íšŒì‚¬ ì§€ì›)"""
    base_criteria = SELECTION_CRITERIA
    
    # companiesê°€ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(companies, str):
        companies = [companies]
    
    # ì„ íƒëœ ëª¨ë“  íšŒì‚¬ì˜ ì¶”ê°€ ê¸°ì¤€ì„ í•©ì¹¨
    all_additional_criteria = ""
    for company in companies:
        additional_criteria = COMPANY_ADDITIONAL_SELECTION_CRITERIA.get(company, "")
        if additional_criteria:
            all_additional_criteria += additional_criteria
    
    return base_criteria + all_additional_criteria

def get_scope_based_criteria(analysis_scope, criteria_type="selection_criteria", keywords=None):
    """ë¶„ì„ ë²”ìœ„ì— ë”°ë¥¸ íŠ¹í™” ê¸°ì¤€ì„ ë°˜í™˜ (í‚¤ì›Œë“œ í¬í•¨)"""
    if not analysis_scope:
        return ""
    
    # ì²« ë²ˆì§¸ ë²”ìœ„ë¥¼ ì£¼ìš” ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš© (ë³¸ì¸íšŒì‚¬ > ê²½ìŸì‚¬ > ì‚°ì—…ë¶„ì•¼ ìˆœì„œë¡œ ìš°ì„ ìˆœìœ„)
    priority_order = ["ë³¸ì¸íšŒì‚¬", "ê²½ìŸì‚¬", "ì‚°ì—…ë¶„ì•¼"]
    selected_scope = None
    
    for scope in priority_order:
        if scope in analysis_scope:
            selected_scope = scope
            break
    
    if selected_scope and selected_scope in ANALYSIS_SCOPE_CRITERIA:
        criteria_template = ANALYSIS_SCOPE_CRITERIA[selected_scope].get(criteria_type, "")
        
        # í‚¤ì›Œë“œê°€ ì œê³µëœ ê²½ìš° í…œí”Œë¦¿ì— ì‚½ì…
        if keywords and "{keywords}" in criteria_template:
            keywords_str = ", ".join(keywords) if isinstance(keywords, list) else str(keywords)
            return criteria_template.format(keywords=keywords_str)
        
        return criteria_template
    
    return ""

def get_scope_based_system_prompts(analysis_scope):
    """ë¶„ì„ ë²”ìœ„ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë°˜í™˜"""
    if not analysis_scope:
        return SYSTEM_PROMPT_1, SYSTEM_PROMPT_2, SYSTEM_PROMPT_3
    
    # ì²« ë²ˆì§¸ ë²”ìœ„ë¥¼ ì£¼ìš” ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš© (ë³¸ì¸íšŒì‚¬ > ê²½ìŸì‚¬ > ì‚°ì—…ë¶„ì•¼ ìˆœì„œë¡œ ìš°ì„ ìˆœìœ„)
    priority_order = ["ë³¸ì¸íšŒì‚¬", "ê²½ìŸì‚¬", "ì‚°ì—…ë¶„ì•¼"]
    selected_scope = None
    
    for scope in priority_order:
        if scope in analysis_scope:
            selected_scope = scope
            break
    
    if selected_scope and selected_scope in ANALYSIS_SCOPE_SYSTEM_PROMPTS:
        scope_prompts = ANALYSIS_SCOPE_SYSTEM_PROMPTS[selected_scope]
        return (
            scope_prompts.get("system_prompt_1", SYSTEM_PROMPT_1),
            scope_prompts.get("system_prompt_2", SYSTEM_PROMPT_2),
            scope_prompts.get("system_prompt_3", SYSTEM_PROMPT_3)
        )
    
    return SYSTEM_PROMPT_1, SYSTEM_PROMPT_2, SYSTEM_PROMPT_3
            
# ì›Œë“œ íŒŒì¼ ìƒì„± í•¨ìˆ˜
def create_word_document(keyword, final_selection, analysis=""):
    # ìƒˆ ì›Œë“œ ë¬¸ì„œ ìƒì„±
    doc = docx.Document()
    
    # ì œëª© ìŠ¤íƒ€ì¼ ì„¤ì •
    title = doc.add_heading(f'PwC ë‰´ìŠ¤ ë¶„ì„ ë³´ê³ ì„œ: {keyword}', level=0)
    for run in title.runs:
        run.font.color.rgb = RGBColor(208, 74, 2)  # PwC ì˜¤ë Œì§€ ìƒ‰ìƒ
    
    # ë¶„ì„ ìš”ì•½ ì¶”ê°€
    if analysis:
        doc.add_heading('íšŒê³„ë²•ì¸ ê´€ì ì˜ ë¶„ì„ ê²°ê³¼', level=1)
        doc.add_paragraph(analysis)
    
    # ì„ ë³„ëœ ì£¼ìš” ë‰´ìŠ¤ ì¶”ê°€
    doc.add_heading('ì„ ë³„ëœ ì£¼ìš” ë‰´ìŠ¤', level=1)
    
    for i, news in enumerate(final_selection):
        p = doc.add_paragraph()
        p.add_run(f"{i+1}. {news['title']}").bold = True
        
        # ë‚ ì§œ ì •ë³´ ì¶”ê°€
        date_str = news.get('date', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')
        date_paragraph = doc.add_paragraph()
        date_paragraph.add_run(f"ë‚ ì§œ: {date_str}").italic = True
        
        # ì„ ì • ì‚¬ìœ  ì¶”ê°€
        reason = news.get('reason', '')
        if reason:
            doc.add_paragraph(f"ì„ ì • ì‚¬ìœ : {reason}")
        
        # í‚¤ì›Œë“œ ì¶”ê°€
        keywords = news.get('keywords', [])
        if keywords:
            doc.add_paragraph(f"í‚¤ì›Œë“œ: {', '.join(keywords)}")
        
        # ê´€ë ¨ ê³„ì—´ì‚¬ ì¶”ê°€
        affiliates = news.get('affiliates', [])
        if affiliates:
            doc.add_paragraph(f"ê´€ë ¨ ê³„ì—´ì‚¬: {', '.join(affiliates)}")
        
        # ì–¸ë¡ ì‚¬ ì¶”ê°€
        press = news.get('press', 'ì•Œ ìˆ˜ ì—†ìŒ')
        doc.add_paragraph(f"ì–¸ë¡ ì‚¬: {press}")
        
        # URL ì¶”ê°€
        url = news.get('url', '')
        if url:
            doc.add_paragraph(f"ì¶œì²˜: {url}")
        
        # êµ¬ë¶„ì„  ì¶”ê°€
        if i < len(final_selection) - 1:
            doc.add_paragraph("").add_run().add_break()
    
    # ë‚ ì§œ ë° í‘¸í„° ì¶”ê°€
    current_date = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
    doc.add_paragraph(f"\në³´ê³ ì„œ ìƒì„±ì¼: {current_date}")
    doc.add_paragraph("Â© 2024 PwC ë‰´ìŠ¤ ë¶„ì„ê¸° | íšŒê³„ë²•ì¸ ê´€ì ì˜ ë‰´ìŠ¤ ë¶„ì„ ë„êµ¬")
    
    return doc

# BytesIO ê°ì²´ë¡œ ì›Œë“œ ë¬¸ì„œ ì €ì¥
def get_binary_file_downloader_html(doc, file_name):
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .title-container {
        display: flex;
        align-items: center;
        gap: 20px;
        margin-bottom: 20px;
    }
    .main-title {
        color: #d04a02;
        font-size: 2.5rem;
        font-weight: 700;
    }
    .news-card {
        background-color: #f9f9f9;
        border-radius: 10px;
        padding: 15px;
        margin-bottom: 15px;
        border-left: 4px solid #d04a02;
    }
    .news-title {
        font-weight: 600;
        font-size: 1.1rem;
    }
    .news-url {
        color: #666;
        font-size: 0.9rem;
    }
    .news-date {
        color: #666;
        font-size: 0.9rem;
        font-style: italic;
        margin-top: 5px;
    }
    .analysis-box {
        background-color: #f5f5ff;
        border-radius: 10px;
        padding: 20px;
        margin: 20px 0;
        border-left: 4px solid #d04a02;
    }
    .subtitle {
        color: #dc582a;
        font-size: 1.3rem;
        font-weight: 600;
        margin-top: 20px;
        margin-bottom: 10px;
    }
    .download-box {
        background-color: #eaf7f0;
        border-radius: 10px;
        padding: 20px;
        margin: 20px 0;
        border-left: 4px solid #00a36e;
        text-align: center;
    }
    .analysis-section {
        background-color: #f8f9fa;
        border-left: 4px solid #d04a02;
        padding: 20px;
        margin: 10px 0;
        border-radius: 5px;
    }
    .selected-news {
        border-left: 4px solid #0077b6;
        padding: 15px;
        margin: 10px 0;
        background-color: #f0f8ff;
        border-radius: 5px;
    }
    .excluded-news {
        color: #666;
        padding: 5px 0;
        margin: 5px 0;
        font-size: 0.9em;
    }
    .news-meta {
        color: #666;
        font-size: 0.9em;
        margin: 3px 0;
    }
    .selection-reason {
        color: #666;
        margin: 5px 0;
        font-size: 0.95em;
    }
    .keywords {
        color: #666;
        font-size: 0.9em;
        margin: 5px 0;
    }
    .affiliates {
        color: #666;
        font-size: 0.9em;
        margin: 5px 0;
    }
    .news-url {
        color: #0077b6;
        font-size: 0.9em;
        margin: 5px 0;
        word-break: break-all;
    }
    .news-title-large {
        font-size: 1.2em;
        font-weight: 600;
        color: #000;
        margin-bottom: 8px;
        line-height: 1.4;
    }
    .news-url {
        color: #0077b6;
        font-size: 0.9em;
        margin: 5px 0 10px 0;
        word-break: break-all;
    }
    .news-summary {
        color: #444;
        font-size: 0.95em;
        margin: 10px 0;
        line-height: 1.4;
    }
    .selection-reason {
        color: #666;
        font-size: 0.95em;
        margin: 10px 0;
        line-height: 1.4;
    }
    .importance-high {
        color: #d04a02;
        font-weight: 700;
        margin: 5px 0;
    }
    .importance-medium {
        color: #0077b6;
        font-weight: 700;
        margin: 5px 0;
    }
    .group-indices {
        color: #666;
        font-size: 0.9em;
    }
    .group-selected {
        color: #00a36e;
        font-weight: 600;
    }
    .group-reason {
        color: #666;
        font-size: 0.9em;
        margin-top: 5px;
    }
    .not-selected-news {
        color: #666;
        padding: 5px 0;
        margin: 5px 0;
        font-size: 0.9em;
    }
    .importance-low {
        color: #666;
        font-weight: 700;
        margin: 5px 0;
    }
    .not-selected-reason {
        color: #666;
        margin: 5px 0;
        font-size: 0.95em;
    }
    .email-preview {
        background-color: white;
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 20px;
        margin: 20px 0;
        overflow-y: auto;
        max-height: 500px;
    }
    .copy-button {
        background-color: #d04a02;
        color: white;
        padding: 10px 20px;
        border: none;
        border-radius: 5px;
        cursor: pointer;
        margin: 10px 0;
    }
    .copy-button:hover {
        background-color: #b33d00;
    }
</style>
""", unsafe_allow_html=True)

# ë¡œê³ ì™€ ì œëª©
col1, col2 = st.columns([1, 5])
with col1:
    # ë¡œê³  í‘œì‹œ
    logo_path = "pwc_logo.png"
    if os.path.exists(logo_path):
        st.image(logo_path, width=100)
    else:
        st.error("ë¡œê³  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— 'pwc_logo.png' íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")

with col2:
    st.markdown("<h1 class='main-title'>PwC ë‰´ìŠ¤ ë¶„ì„ê¸°</h1>", unsafe_allow_html=True)
    st.markdown("íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” AI ë„êµ¬")

# ê¸°ë³¸ ì„ íƒ ì¹´í…Œê³ ë¦¬ë¥¼ Anchorë¡œ ì„¤ì •
COMPANIES = COMPANY_CATEGORIES["Anchor"]

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ê°€ì¥ ë¨¼ì € ì‹¤í–‰)
if 'company_keyword_map' not in st.session_state:
    st.session_state.company_keyword_map = COMPANY_KEYWORD_MAP.copy()

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title("ğŸ” ë¶„ì„ ì„¤ì •")

# 0ë‹¨ê³„: ê¸°ë³¸ ì„¤ì •
st.sidebar.markdown("### ğŸ“‹ 0ë‹¨ê³„: ê¸°ë³¸ ì„¤ì •")

# ê¸°ì‚¬ ì›ë¬¸ ìš”ì•½ ì˜µì…˜
enable_article_summary = st.sidebar.checkbox(
    "ğŸ“„ ì„ ì •ëœ ê¸°ì‚¬ ì›ë¬¸ ìš”ì•½",
    value=False,
    help="ì„ ì •ëœ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì›ë¬¸ì„ ìŠ¤í¬ë˜í•‘í•˜ì—¬ AI ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤. (ì‹œê°„ì´ ì¶”ê°€ë¡œ ì†Œìš”ë©ë‹ˆë‹¤)"
)

# ìœ íš¨ ì–¸ë¡ ì‚¬ ì„¤ì • (ìˆ¨ê¹€ ì²˜ë¦¬)
with st.sidebar.expander("ğŸ“° ìœ íš¨ ì–¸ë¡ ì‚¬ ì„¤ì • (ê³ ê¸‰)", expanded=False):
    valid_press_dict = st.text_area(
        "ìœ íš¨ ì–¸ë¡ ì‚¬ ì„¤ì •",
        value="""ì¡°ì„ ì¼ë³´: ["ì¡°ì„ ì¼ë³´", "chosun", "chosun.com"]
    ì¤‘ì•™ì¼ë³´: ["ì¤‘ì•™ì¼ë³´", "joongang", "joongang.co.kr", "joins.com"]
    ë™ì•„ì¼ë³´: ["ë™ì•„ì¼ë³´", "donga", "donga.com"]
    ì¡°ì„ ë¹„ì¦ˆ: ["ì¡°ì„ ë¹„ì¦ˆ", "chosunbiz", "biz.chosun.com"]
    ë§¤ê±°ì§„í•œê²½: ["ë§¤ê±°ì§„í•œê²½", "magazine.hankyung", "magazine.hankyung.com"]
    í•œêµ­ê²½ì œ: ["í•œêµ­ê²½ì œ", "í•œê²½", "hankyung", "hankyung.com", "í•œê²½ë‹·ì»´"]
    ë§¤ì¼ê²½ì œ: ["ë§¤ì¼ê²½ì œ", "ë§¤ê²½", "mk", "mk.co.kr"]
    ì—°í•©ë‰´ìŠ¤: ["ì—°í•©ë‰´ìŠ¤", "yna", "yna.co.kr"]
    íŒŒì´ë‚¸ì…œë‰´ìŠ¤: ["íŒŒì´ë‚¸ì…œë‰´ìŠ¤", "fnnews", "fnnews.com"]
    ë°ì¼ë¦¬íŒœ: ["ë°ì¼ë¦¬íŒœ", "dailypharm", "dailypharm.com"]
    ITì¡°ì„ : ["itì¡°ì„ ", "it.chosun.com", "itchosun"]
    ë¨¸ë‹ˆíˆ¬ë°ì´: ["ë¨¸ë‹ˆíˆ¬ë°ì´", "mt", "mt.co.kr"]
    ë¹„ì¦ˆë‹ˆìŠ¤í¬ìŠ¤íŠ¸: ["ë¹„ì¦ˆë‹ˆìŠ¤í¬ìŠ¤íŠ¸", "businesspost", "businesspost.co.kr"]
    ì´ë°ì¼ë¦¬: ["ì´ë°ì¼ë¦¬", "edaily", "edaily.co.kr"]
    ì•„ì‹œì•„ê²½ì œ: ["ì•„ì‹œì•„ê²½ì œ", "asiae", "asiae.co.kr"]
    ë‰´ìŠ¤í•Œ: ["ë‰´ìŠ¤í•Œ", "newspim", "newspim.com"]
    ë‰´ì‹œìŠ¤: ["ë‰´ì‹œìŠ¤", "newsis", "newsis.com"]
    í—¤ëŸ´ë“œê²½ì œ: ["í—¤ëŸ´ë“œê²½ì œ", "herald", "heraldcorp", "heraldcorp.com"]""",
        help="ë¶„ì„ì— í¬í•¨í•  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ì™€ ê·¸ ë³„ì¹­ì„ ì„¤ì •í•˜ì„¸ìš”. í˜•ì‹: 'ì–¸ë¡ ì‚¬: [ë³„ì¹­1, ë³„ì¹­2, ...]'",
        key="valid_press_dict"
    )

# ì¶”ê°€ ì–¸ë¡ ì‚¬ ì„¤ì • (ì¬í‰ê°€ ì‹œì—ë§Œ ì‚¬ìš©ë¨) - ìˆ¨ê¹€ ì²˜ë¦¬
with st.sidebar.expander("ğŸ“° ì¶”ê°€ ì–¸ë¡ ì‚¬ ì„¤ì • (ì¬í‰ê°€ìš©)", expanded=False):
    additional_press_dict = st.text_area(
        "ì¶”ê°€ ì–¸ë¡ ì‚¬ ì„¤ì • (ì¬í‰ê°€ ì‹œì—ë§Œ ì‚¬ìš©)",
        value="""ì² ê°•ê¸ˆì†ì‹ ë¬¸: ["ì² ê°•ê¸ˆì†ì‹ ë¬¸", "snmnews", "snmnews.com"]
    ì—ë„ˆì§€ì‹ ë¬¸: ["ì—ë„ˆì§€ì‹ ë¬¸", "energy-news", "energy-news.co.kr"]
    ì´ì½”ë…¸ë¯¹ë°ì¼ë¦¬: ["ì´ì½”ë…¸ë¯¹ë°ì¼ë¦¬", "economidaily", "economidaily.com"]""",
        help="ê¸°ë³¸ ì–¸ë¡ ì‚¬ì—ì„œ ë‰´ìŠ¤ê°€ ì„ íƒë˜ì§€ ì•Šì„ ê²½ìš°, ì¬í‰ê°€ ë‹¨ê³„ì—ì„œ ì¶”ê°€ë¡œ ê³ ë ¤í•  ì–¸ë¡ ì‚¬ì™€ ë³„ì¹­ì„ ì„¤ì •í•˜ì„¸ìš”. í˜•ì‹: 'ì–¸ë¡ ì‚¬: [ë³„ì¹­1, ë³„ì¹­2, ...]'",
        key="additional_press_dict"
    )

# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")

# ë‚ ì§œ í•„í„° ì„¤ì •
st.sidebar.markdown("### ğŸ“… ë‚ ì§œ í•„í„°")

# í˜„ì¬ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
now = datetime.now()

# ê¸°ë³¸ ì‹œì‘ ë‚ ì§œ/ì‹œê°„ ê³„ì‚°
default_start_date = now - timedelta(days=1)

# Set time to 8:00 AM for both start and end - í•œêµ­ ì‹œê°„ ê¸°ì¤€
start_datetime = datetime.combine(default_start_date.date(), 
                                    datetime.strptime("08:00", "%H:%M").time(), KST)
end_datetime = datetime.combine(now.date(), 
                                datetime.strptime("08:00", "%H:%M").time(), KST)

col1, col2 = st.sidebar.columns(2)
with col1:
    start_date = st.date_input(
        "ì‹œì‘ ë‚ ì§œ",
        value=default_start_date.date(),
        help="ì´ ë‚ ì§œë¶€í„° ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì›”ìš”ì¼ì¸ ê²½ìš° ì§€ë‚œ ê¸ˆìš”ì¼, ê·¸ ì™¸ì—ëŠ” ì „ì¼ë¡œ ìë™ ì„¤ì •ë©ë‹ˆë‹¤."
    )
    start_time = st.time_input(
        "ì‹œì‘ ì‹œê°„",
        value=start_datetime.time(),
        help="ì‹œì‘ ë‚ ì§œì˜ êµ¬ì²´ì ì¸ ì‹œê°„ì„ ì„¤ì •í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ ì˜¤ì „ 8ì‹œì…ë‹ˆë‹¤."
    )
with col2:
    end_date = st.date_input(
        "ì¢…ë£Œ ë‚ ì§œ",
        value=now.date(),
        help="ì´ ë‚ ì§œê¹Œì§€ì˜ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    )
    end_time = st.time_input(
        "ì¢…ë£Œ ì‹œê°„",
        value=end_datetime.time(),
        help="ì¢…ë£Œ ë‚ ì§œì˜ êµ¬ì²´ì ì¸ ì‹œê°„ì„ ì„¤ì •í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ ì˜¤ì „ 8ì‹œì…ë‹ˆë‹¤."
    )

# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")

# 1ë‹¨ê³„: ì œì™¸ íŒë‹¨ ê¸°ì¤€

# ê¸°ì—… ì„ íƒ ì„¹ì…˜ ì œëª©
st.sidebar.markdown("### ğŸ¢ ë¶„ì„í•  ê¸°ì—… ì„ íƒ")

# í˜„ëŒ€ì°¨ê·¸ë£¹ ë¶„ì„ êµ¬ì¡° ì‚¬ìš©
st.sidebar.markdown("#### ğŸ”¥ í˜„ëŒ€ì°¨ê·¸ë£¹ ë¶„ì„ êµ¬ì¡°")

# í˜„ëŒ€ì°¨ê·¸ë£¹ ì„ íƒ (í˜„ì¬ëŠ” í•˜ë‚˜ë§Œ ìˆìŒ)
selected_group = st.sidebar.selectbox(
    "ê·¸ë£¹ ì„ íƒ",
    options=list(COMPANY_STRUCTURE_NEW.keys()),
    index=0,
    help="ë¶„ì„í•  ê¸°ì—… ê·¸ë£¹ì„ ì„ íƒí•˜ì„¸ìš”"
)

# ë¶„ì„ ë²”ìœ„ ì„ íƒ
analysis_scope = st.sidebar.multiselect(
    "ğŸ“Š ë¶„ì„ ë²”ìœ„ ì„ íƒ",
    options=["ë³¸ì¸íšŒì‚¬", "ê²½ìŸì‚¬", "ì‚°ì—…ë¶„ì•¼"],
    default=["ì‚°ì—…ë¶„ì•¼"],
    help="ì–´ë–¤ ë²”ìœ„ì˜ ë‰´ìŠ¤ë¥¼ ë¶„ì„í• ì§€ ì„ íƒí•˜ì„¸ìš”"
)

# ì„ íƒëœ í‚¤ì›Œë“œë“¤ì„ ìˆ˜ì§‘
selected_keywords = []

if "ë³¸ì¸íšŒì‚¬" in analysis_scope:
    st.sidebar.markdown("##### ğŸ  ë³¸ì¸íšŒì‚¬")
    own_company_types = st.sidebar.multiselect(
        "ê³„ì—´ì‚¬ ìœ í˜• ì„ íƒ",
        options=list(COMPANY_STRUCTURE_NEW[selected_group]["ë³¸ì¸íšŒì‚¬"].keys()),
        default=["í•µì‹¬ê³„ì—´ì‚¬"],
        help="í¬í•¨í•  ê³„ì—´ì‚¬ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”"
    )
    
    for comp_type in own_company_types:
        companies = COMPANY_STRUCTURE_NEW[selected_group]["ë³¸ì¸íšŒì‚¬"][comp_type]
        selected_companies_in_type = st.sidebar.multiselect(
            f"{comp_type}",
            options=companies,
            default=companies[:3] if len(companies) > 3 else companies,
            key=f"own_{comp_type}"
        )
        selected_keywords.extend(selected_companies_in_type)

if "ê²½ìŸì‚¬" in analysis_scope:
    st.sidebar.markdown("##### âš”ï¸ ê²½ìŸì‚¬")
    competitor_types = st.sidebar.multiselect(
        "ê²½ìŸì‚¬ ìœ í˜• ì„ íƒ",
        options=list(COMPANY_STRUCTURE_NEW[selected_group]["ê²½ìŸì‚¬"].keys()),
        default=["êµ­ë‚´ê²½ìŸì‚¬"],
        help="ë¶„ì„í•  ê²½ìŸì‚¬ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”"
    )
    
    for comp_type in competitor_types:
        companies = COMPANY_STRUCTURE_NEW[selected_group]["ê²½ìŸì‚¬"][comp_type]
        selected_companies_in_type = st.sidebar.multiselect(
            f"{comp_type}",
            options=companies,
            default=companies[:2] if len(companies) > 2 else companies,
            key=f"comp_{comp_type}"
        )
        selected_keywords.extend(selected_companies_in_type)

if "ì‚°ì—…ë¶„ì•¼" in analysis_scope:
    st.sidebar.markdown("##### ğŸ­ ì‚°ì—…ë¶„ì•¼")
    industry_fields = st.sidebar.multiselect(
        "ì‚°ì—… ë¶„ì•¼ ì„ íƒ",
        options=list(COMPANY_STRUCTURE_NEW[selected_group]["ì‚°ì—…ë¶„ì•¼"].keys()),
        default=["ë°°í„°ë¦¬_Cell_Module_System","ë°°í„°ë¦¬_Charging_Simulation","ì „ë™í™”_Motor_drive","ì „ë™í™”_Control_Electronics","ë‚´ì—°ê¸°ê´€_ì—°ì†Œ","ì—°ë£Œ_ëŒ€ì²´ì—°ë£Œ","ë°°ì¶œê°€ìŠ¤_í›„ì²˜ë¦¬","êµ¬ë™ê³„_ë³€ì†ê¸°","í•˜ì´ë¸Œë¦¬ë“œ_ì—´ê´€ë¦¬","ì‹œë®¬ë ˆì´ì…˜_ì œì–´","ê¸°íƒ€"],
        help="ë¶„ì„í•  ì‚°ì—… ë¶„ì•¼ë¥¼ ì„ íƒí•˜ì„¸ìš”. ê° ë¶„ì•¼ë³„ë¡œ ì„¸ë¶€ í‚¤ì›Œë“œë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    
    # ê° ì‚°ì—…ë¶„ì•¼ë³„ë¡œ ì„¸ë¶€ í‚¤ì›Œë“œ ì„ íƒ ê°€ëŠ¥í•˜ê²Œ í•¨
    for field in industry_fields:
        with st.sidebar.expander(f"ğŸ”§ {field} ì„¸ë¶€ í‚¤ì›Œë“œ ì„¤ì •"):
            # ìƒˆë¡œìš´ ì˜ì–´ í‚¤ì›Œë“œ êµ¬ì¡°ì—ì„œ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
            field_keywords = COMPANY_STRUCTURE_NEW[selected_group]["ì‚°ì—…ë¶„ì•¼"][field]
            selected_field_keywords = st.multiselect(
                f"ğŸ‡ºğŸ‡¸ {field} í‚¤ì›Œë“œ",
                options=field_keywords,
                default=field_keywords,  # ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  í‚¤ì›Œë“œ ì„ íƒ
                key=f"field_{field}"
            )
            
            # ì„ íƒëœ í‚¤ì›Œë“œë“¤ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            if selected_field_keywords:
                st.session_state.company_keyword_map[field] = selected_field_keywords
                selected_keywords.append(field)  # ë¶„ì•¼ ì´ë¦„ì„ í‚¤ì›Œë“œë¡œ ì¶”ê°€
            else:
                # ì•„ë¬´ê²ƒë„ ì„ íƒí•˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ë¶„ì•¼ ì´ë¦„ë§Œ ì‚¬ìš©
                st.session_state.company_keyword_map[field] = [field]
                selected_keywords.append(field)
            
            # ì„ íƒëœ í‚¤ì›Œë“œ ìš”ì•½ í‘œì‹œ
            if selected_field_keywords:
                st.info(f"ì„ íƒë¨: {len(selected_field_keywords)}ê°œ í‚¤ì›Œë“œ")

# ìµœì¢… ì„ íƒëœ í‚¤ì›Œë“œë“¤ì„ companiesë¡œ ì„¤ì •
selected_companies = selected_keywords[:10]  # ìµœëŒ€ 10ê°œ ì œí•œ

# í‚¤ì›Œë“œ ë§µ ì—…ë°ì´íŠ¸ - ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë¨ (ì‚°ì—…ë¶„ì•¼ëŠ” ì‚¬ìš©ì ì„ íƒìœ¼ë¡œ, ì¼ë°˜ í‚¤ì›Œë“œëŠ” ìê¸° ìì‹ )
for keyword in selected_companies:
    if 'company_keyword_map' not in st.session_state:
            st.session_state.company_keyword_map = {}
        
    # ì‚°ì—…ë¶„ì•¼ê°€ ì•„ë‹Œ ì¼ë°˜ í‚¤ì›Œë“œëŠ” ìê¸° ìì‹ ë§Œ í¬í•¨
    if keyword not in COMPANY_STRUCTURE_NEW[selected_group]["ì‚°ì—…ë¶„ì•¼"]:
        st.session_state.company_keyword_map[keyword] = [keyword]





# ì„ íƒëœ í‚¤ì›Œë“œ ë¯¸ë¦¬ë³´ê¸°
st.sidebar.markdown("### ğŸ” ì„ íƒëœ í‚¤ì›Œë“œ ë¯¸ë¦¬ë³´ê¸°")
st.sidebar.markdown(f"ì´ **{len(selected_companies)}ê°œ** í‚¤ì›Œë“œê°€ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì„¸ì…˜ ìƒíƒœëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì´ˆê¸°í™”ë¨

# ì¶”ê°€ í‚¤ì›Œë“œ ì„¤ì •
st.sidebar.markdown("#### â• ì¶”ê°€ í‚¤ì›Œë“œ ì„¤ì •")
additional_keywords_text = st.sidebar.text_area(
    "ì§ì ‘ í‚¤ì›Œë“œ ì¶”ê°€",
    value="",
    placeholder="í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3\n(ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥)",
    help="ìœ„ì—ì„œ ì„ íƒí•œ í‚¤ì›Œë“œ ì™¸ì— ì¶”ê°€ë¡œ ë¶„ì„í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
    key="additional_keywords"
)

# ì¶”ê°€ í‚¤ì›Œë“œ ì²˜ë¦¬
additional_keywords = []
if additional_keywords_text.strip():
    # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í‚¤ì›Œë“œë“¤ì„ íŒŒì‹±
    additional_keywords = [kw.strip() for kw in additional_keywords_text.split(',') if kw.strip()]
    
    # ì¶”ê°€ í‚¤ì›Œë“œë“¤ì„ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
    for keyword in additional_keywords:
        if keyword not in st.session_state.company_keyword_map:
            st.session_state.company_keyword_map[keyword] = [keyword]

# ìµœì¢… í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (ì„ íƒëœ í‚¤ì›Œë“œ + ì¶”ê°€ í‚¤ì›Œë“œ)
final_selected_companies = selected_companies + additional_keywords
final_selected_companies = list(dict.fromkeys(final_selected_companies))  # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ìˆœì„œ ìœ ì§€
final_selected_companies = final_selected_companies[:15]  # ìµœëŒ€ 15ê°œë¡œ í™•ì¥

# ë¯¸ë¦¬ë³´ê¸° ë²„íŠ¼ - ëª¨ë“  ê²€ìƒ‰ì–´ í™•ì¸
with st.sidebar.expander("ğŸ” ì „ì²´ ê²€ìƒ‰ í‚¤ì›Œë“œ ë¯¸ë¦¬ë³´ê¸°"):
    # ì„ íƒëœ í‚¤ì›Œë“œë“¤ê³¼ ì‹¤ì œ ê²€ìƒ‰ì–´ë“¤ì„ í‘œì‹œ
    st.markdown("**ğŸ“Š ì„ íƒëœ ë¶„ì„ ëŒ€ìƒ**")
    
    if len(selected_companies) > 0:
        st.markdown("**ğŸ¢ êµ¬ì¡° ê¸°ë°˜ ì„ íƒ:**")
        for i, keyword in enumerate(selected_companies, 1):
            st.markdown(f"**{i}. {keyword}**")
            # ì‹¤ì œ ê²€ìƒ‰ì— ì‚¬ìš©ë  í‚¤ì›Œë“œë“¤ í‘œì‹œ
            if 'company_keyword_map' in st.session_state:
                search_terms = st.session_state.company_keyword_map.get(keyword, [keyword])
                if len(search_terms) > 1:
                    st.write(f"   ğŸ‡ºğŸ‡¸ ì˜ì–´ í‚¤ì›Œë“œ: {', '.join(search_terms)}")
                    st.write(f"   ğŸ“Š ì´ {len(search_terms)}ê°œ í‚¤ì›Œë“œ")
                else:
                    st.write(f"   ğŸ” ê²€ìƒ‰ì–´: {search_terms[0]}")
    
    if len(additional_keywords) > 0:
        st.markdown("**â• ì§ì ‘ ì¶”ê°€:**")
        for i, keyword in enumerate(additional_keywords, len(selected_companies) + 1):
            st.markdown(f"**{i}. {keyword}**")
            st.write(f"   ğŸ” ê²€ìƒ‰ì–´: {keyword}")
    
    if len(final_selected_companies) == 0:
        st.info("ë¶„ì„ ëŒ€ìƒì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        st.success(f"ì´ **{len(final_selected_companies)}ê°œ** í‚¤ì›Œë“œë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")

# ì„ íƒëœ í‚¤ì›Œë“œë“¤ì„ í†µí•© (ê²€ìƒ‰ìš©) - ìµœì¢… ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
keywords = final_selected_companies

# ì¤‘ë³µ ì œê±°ëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë¨
# keywords = list(set(keywords))

# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")



# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")

# GPT ëª¨ë¸ ì„ íƒ ì„¹ì…˜
st.sidebar.markdown("### ğŸ¤– GPT ëª¨ë¸ ì„ íƒ")

selected_model = st.sidebar.selectbox(
    "ë¶„ì„ì— ì‚¬ìš©í•  GPT ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
    options=list(GPT_MODELS.keys()),
    index=list(GPT_MODELS.keys()).index(DEFAULT_GPT_MODEL) if DEFAULT_GPT_MODEL in GPT_MODELS else 0,
    format_func=lambda x: f"{x} - {GPT_MODELS[x]}",
    help="ê° ëª¨ë¸ì˜ íŠ¹ì„±:\n" + "\n".join([f"â€¢ {k}: {v}" for k, v in GPT_MODELS.items()])
)

# ëª¨ë¸ ì„¤ëª… í‘œì‹œ
st.sidebar.markdown(f"""
<div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 20px;'>
    <strong>ì„ íƒëœ ëª¨ë¸:</strong> {selected_model}<br>
    <strong>íŠ¹ì§•:</strong> {GPT_MODELS[selected_model]}
</div>
""", unsafe_allow_html=True)

# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")

# ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ - ê³ ì • ê°’ìœ¼ë¡œ ì„¤ì •
max_results = 100

# AI í”„ë¡¬í”„íŠ¸ ë° ë¶„ì„ ê¸°ì¤€ ì„¤ì •
st.sidebar.markdown("### ğŸ¤– AI ë¶„ì„ ë‹¨ê³„ë³„ ì„¤ì •")

# í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°ìš© ë¶„ì„ ë²”ìœ„ ì„ íƒ
prompt_preview_scope = st.sidebar.selectbox(
    "ë¶„ì„ ë²”ìœ„ ì„ íƒ",
    options=["ê¸°ë³¸", "ë³¸ì¸íšŒì‚¬", "ê²½ìŸì‚¬", "ì‚°ì—…ë¶„ì•¼"],
    index=0,
    help="ì–´ë–¤ ë¶„ì„ ë²”ìœ„ì˜ AI í”„ë¡¬í”„íŠ¸ì™€ ê¸°ì¤€ì„ ë¯¸ë¦¬ë³´ê¸°í• ì§€ ì„ íƒí•˜ì„¸ìš”"
)

# ì„ íƒëœ ë²”ìœ„ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ì™€ ê¸°ì¤€ ê°€ì ¸ì˜¤ê¸°
if prompt_preview_scope == "ê¸°ë³¸":
    preview_system_prompt_1 = SYSTEM_PROMPT_1
    preview_system_prompt_2 = SYSTEM_PROMPT_2
    preview_system_prompt_3 = SYSTEM_PROMPT_3
    preview_exclusion_criteria = EXCLUSION_CRITERIA
    preview_selection_criteria = SELECTION_CRITERIA
else:
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    preview_prompts = get_scope_based_system_prompts([prompt_preview_scope])
    preview_system_prompt_1 = preview_prompts[0]
    preview_system_prompt_2 = preview_prompts[1] 
    preview_system_prompt_3 = preview_prompts[2]
    
    # ë¶„ì„ ê¸°ì¤€
    dummy_keywords = ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
    preview_exclusion_criteria = EXCLUSION_CRITERIA + "\n\n" + get_scope_based_criteria([prompt_preview_scope], "exclusion_criteria", dummy_keywords)
    preview_selection_criteria = get_scope_based_criteria([prompt_preview_scope], "selection_criteria", dummy_keywords)
    if not preview_selection_criteria:
        preview_selection_criteria = SELECTION_CRITERIA

# ë‹¨ê³„ë³„ ì„¤ì •
st.sidebar.markdown(f"#### ğŸ“‹ 1ë‹¨ê³„: ì œì™¸ íŒë‹¨ ({prompt_preview_scope})")

# 1ë‹¨ê³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
system_prompt_1 = st.sidebar.text_area(
    "ğŸ¤– ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
    value=preview_system_prompt_1,
    help=f"{prompt_preview_scope} ë²”ìœ„ì˜ 1ë‹¨ê³„ ì œì™¸ íŒë‹¨ì— ì‚¬ìš©ë˜ëŠ” AI ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤.",
    key=f"system_prompt_1_{prompt_preview_scope}",
    height=200
)

# 1ë‹¨ê³„ ë¶„ì„ ê¸°ì¤€ (ìœ ì € í”„ë¡¬í”„íŠ¸)
exclusion_criteria = st.sidebar.text_area(
    "ğŸ‘¤ ë¶„ì„ ê¸°ì¤€ (ìœ ì € í”„ë¡¬í”„íŠ¸)",
    value=preview_exclusion_criteria,
    help=f"{prompt_preview_scope} ë²”ìœ„ì˜ ì œì™¸ ê¸°ì¤€ì…ë‹ˆë‹¤. ì‹¤ì œ ë¶„ì„ ì‹œ ì„ íƒëœ í‚¤ì›Œë“œê°€ ì ìš©ë©ë‹ˆë‹¤.",
    key=f"exclusion_criteria_{prompt_preview_scope}",
    height=200
)

st.sidebar.markdown("---")
st.sidebar.markdown(f"#### ğŸ“‹ 2ë‹¨ê³„: ê·¸ë£¹í•‘ ({prompt_preview_scope})")

# 2ë‹¨ê³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
system_prompt_2 = st.sidebar.text_area(
    "ğŸ¤– ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
    value=preview_system_prompt_2,
    help=f"{prompt_preview_scope} ë²”ìœ„ì˜ 2ë‹¨ê³„ ê·¸ë£¹í•‘ì— ì‚¬ìš©ë˜ëŠ” AI ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤.",
    key=f"system_prompt_2_{prompt_preview_scope}",
    height=200
)

# 2ë‹¨ê³„ ë¶„ì„ ê¸°ì¤€ (ìœ ì € í”„ë¡¬í”„íŠ¸)
duplicate_handling = st.sidebar.text_area(
    "ğŸ‘¤ ë¶„ì„ ê¸°ì¤€ (ìœ ì € í”„ë¡¬í”„íŠ¸)",
    value=DUPLICATE_HANDLING,
    help="ì¤‘ë³µëœ ë‰´ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ê¸°ì¤€ì„ ì„¤ì •í•˜ì„¸ìš”.",
    key=f"duplicate_handling_{prompt_preview_scope}",
    height=200
)

st.sidebar.markdown("---")
st.sidebar.markdown(f"#### ğŸ“‹ 3ë‹¨ê³„: ì¤‘ìš”ë„ í‰ê°€ ({prompt_preview_scope})")

# 3ë‹¨ê³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
system_prompt_3 = st.sidebar.text_area(
    "ğŸ¤– ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
    value=preview_system_prompt_3,
    help=f"{prompt_preview_scope} ë²”ìœ„ì˜ 3ë‹¨ê³„ ì¤‘ìš”ë„ í‰ê°€ì— ì‚¬ìš©ë˜ëŠ” AI ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤.",
    key=f"system_prompt_3_{prompt_preview_scope}",
    height=200
)

# 3ë‹¨ê³„ ë¶„ì„ ê¸°ì¤€ (ìœ ì € í”„ë¡¬í”„íŠ¸)
selection_criteria = st.sidebar.text_area(
    "ğŸ‘¤ ë¶„ì„ ê¸°ì¤€ (ìœ ì € í”„ë¡¬í”„íŠ¸)",
    value=preview_selection_criteria,
    help=f"{prompt_preview_scope} ë²”ìœ„ì˜ ì„ íƒ ê¸°ì¤€ì…ë‹ˆë‹¤. ì‹¤ì œ ë¶„ì„ ì‹œ ì„ íƒëœ í‚¤ì›Œë“œê°€ ì ìš©ë©ë‹ˆë‹¤.",
    key=f"selection_criteria_{prompt_preview_scope}",
    height=200
)

# ì‘ë‹µ í˜•ì‹ ì„¤ì •
response_format = st.sidebar.text_area(
    "ğŸ“ ì‘ë‹µ í˜•ì‹",
    value="""ì„ íƒëœ ë‰´ìŠ¤ ì¸ë±ìŠ¤: [1, 3, 5]ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.

ê° ì„ íƒëœ ë‰´ìŠ¤ì— ëŒ€í•´:
ì œëª©: (ë‰´ìŠ¤ ì œëª©)
ì–¸ë¡ ì‚¬: (ì–¸ë¡ ì‚¬ëª…)
ë°œí–‰ì¼: (ë°œí–‰ì¼ì)
ì„ ì • ì‚¬ìœ : (êµ¬ì²´ì ì¸ ì„ ì • ì´ìœ )
ë¶„ì„ í‚¤ì›Œë“œ: (í•´ë‹¹ ê¸°ì—… ê·¸ë£¹ì˜ ì£¼ìš” ê³„ì—´ì‚¬ë“¤)

[ì œì™¸ëœ ì£¼ìš” ë‰´ìŠ¤]
ì œì™¸ëœ ì¤‘ìš” ë‰´ìŠ¤ë“¤ì— ëŒ€í•´:
ì¸ë±ìŠ¤: (ë‰´ìŠ¤ ì¸ë±ìŠ¤)
ì œëª©: (ë‰´ìŠ¤ ì œëª©)
ì œì™¸ ì‚¬ìœ : (êµ¬ì²´ì ì¸ ì œì™¸ ì´ìœ )""",
    help="ë¶„ì„ ê²°ê³¼ì˜ ì¶œë ¥ í˜•ì‹ì„ ì„¤ì •í•˜ì„¸ìš”.",
    key="response_format",
    height=200
)

# ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
analysis_prompt = f"""
ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ì˜ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ ë‰´ìŠ¤ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ì„¸ìš”. 

[ì„ íƒ ê¸°ì¤€]
{selection_criteria}

[ì œì™¸ ëŒ€ìƒ]
{exclusion_criteria}

[ì‘ë‹µ ìš”êµ¬ì‚¬í•­]
1. ì„ íƒ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ” ë‰´ìŠ¤ê°€ ë§ë‹¤ë©´ ìµœëŒ€ 3ê°œê¹Œì§€ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤.
2. ì„ íƒ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ” ë‰´ìŠ¤ê°€ ì—†ë‹¤ë©´, ê·¸ ì´ìœ ë¥¼ ëª…í™•íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.

[ì‘ë‹µ í˜•ì‹]
ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

{{
    "selected_news": [
        {{
            "index": 1,
            "title": "ë‰´ìŠ¤ ì œëª©",
            "press": "ì–¸ë¡ ì‚¬ëª…",
            "date": "ë°œí–‰ì¼ì",
            "reason": "ì„ ì • ì‚¬ìœ ",
            "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
        }},
        ...
    ],
    "excluded_news": [
        {{
            "index": 2,
            "title": "ë‰´ìŠ¤ ì œëª©",
            "reason": "ì œì™¸ ì‚¬ìœ "
        }},
        ...
    ]
}}

[ìœ íš¨ ì–¸ë¡ ì‚¬]
{valid_press_dict}

[ì¤‘ë³µ ì²˜ë¦¬ ê¸°ì¤€]
{duplicate_handling}
"""

# ë©”ì¸ ì»¨í…ì¸ 
if st.button("ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘", type="primary"):
    # ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìœ„í•œ ì „ì²´ ë‚´ìš© ì €ì¥
    email_content = "[Client Intelligence]\n\n"
    
    # ëª¨ë“  í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    all_results = {}
    
    for i, company in enumerate(final_selected_companies, 1):
        with st.spinner(f"'{company}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            # í•´ë‹¹ íšŒì‚¬ì˜ ì—°ê´€ í‚¤ì›Œë“œ í™•ì¥ (ì„¸ì…˜ ìƒíƒœì—ì„œ ê°€ì ¸ì˜´)
            company_keywords = st.session_state.company_keyword_map.get(company, [company])
            
            # ì—°ê´€ í‚¤ì›Œë“œ í‘œì‹œ
            st.write(f"'{company}' ì—°ê´€ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ ì¤‘: {', '.join(company_keywords)}")
            
            # ë²”ìœ„ë³„ íŠ¹í™” ê¸°ì¤€ ì ìš©
            if 'analysis_scope' in locals():
                # ë²”ìœ„ë³„ íŠ¹í™” ê¸°ì¤€ ì ìš© (ì‹¤ì œ ê²€ìƒ‰ í‚¤ì›Œë“œ í¬í•¨)
                scope_selection_criteria = get_scope_based_criteria(analysis_scope, "selection_criteria", company_keywords)
                scope_exclusion_criteria = get_scope_based_criteria(analysis_scope, "exclusion_criteria", company_keywords)
                
                # ë²”ìœ„ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì ìš©
                scope_system_prompt_1, scope_system_prompt_2, scope_system_prompt_3 = get_scope_based_system_prompts(analysis_scope)
                
                # ë²”ìœ„ë³„ ê¸°ì¤€ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ê¸°ì¤€ ì‚¬ìš©
                if scope_selection_criteria:
                    enhanced_selection_criteria = scope_selection_criteria
                else:
                    enhanced_selection_criteria = selection_criteria
                    
                if scope_exclusion_criteria:
                    enhanced_exclusion_criteria = exclusion_criteria + "\n\n" + scope_exclusion_criteria
                else:
                    enhanced_exclusion_criteria = exclusion_criteria
                    
                # ì¤‘ë³µ ì²˜ë¦¬ëŠ” ê¸°ë³¸ ê¸°ì¤€ ì‚¬ìš©
                enhanced_duplicate_handling = duplicate_handling
                
                # í˜„ì¬ ì„ íƒëœ ë¶„ì„ ë²”ìœ„ í™•ì¸
                priority_order = ["ë³¸ì¸íšŒì‚¬", "ê²½ìŸì‚¬", "ì‚°ì—…ë¶„ì•¼"]
                selected_scope = None
                for scope in priority_order:
                    if scope in analysis_scope:
                        selected_scope = scope
                        break
                
                st.info(f"ğŸ¯ ë¶„ì„ ë²”ìœ„ë³„ íŠ¹í™” ê¸°ì¤€ ì ìš©: {', '.join(analysis_scope)}")
                st.info(f"ğŸ” ì‹¤ì œ ê²€ìƒ‰ í‚¤ì›Œë“œ: {', '.join(company_keywords)}")
                if selected_scope:
                    st.info(f"ğŸ¤– ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë³€ê²½: {selected_scope} ë¶„ì„ ëª¨ë“œ")
                
            else:
                # analysis_scopeê°€ ì—†ëŠ” ê²½ìš°
                scope_system_prompt_1, scope_system_prompt_2, scope_system_prompt_3 = SYSTEM_PROMPT_1, SYSTEM_PROMPT_2, SYSTEM_PROMPT_3
                
                base_exclusion = exclusion_criteria
                base_duplicate = duplicate_handling
                base_selection = selection_criteria
                
                # í•´ë‹¹ íšŒì‚¬ì˜ ì¶”ê°€ íŠ¹í™” ê¸°ì¤€ë§Œ ê°€ì ¸ì˜¤ê¸° (ì„¸ì…˜ ìƒíƒœì—ì„œ)
                # ì„¸ì…˜ ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°ë¥¼ ìœ„í•œ ì•ˆì „ì¥ì¹˜
                if 'company_additional_exclusion_criteria' not in st.session_state:
                    st.session_state.company_additional_exclusion_criteria = COMPANY_ADDITIONAL_EXCLUSION_CRITERIA.copy()
                if 'company_additional_duplicate_handling' not in st.session_state:
                    st.session_state.company_additional_duplicate_handling = COMPANY_ADDITIONAL_DUPLICATE_HANDLING.copy()
                if 'company_additional_selection_criteria' not in st.session_state:
                    st.session_state.company_additional_selection_criteria = COMPANY_ADDITIONAL_SELECTION_CRITERIA.copy()
                    
                company_additional_exclusion = st.session_state.company_additional_exclusion_criteria.get(company, "")
                company_additional_duplicate = st.session_state.company_additional_duplicate_handling.get(company, "")
                company_additional_selection = st.session_state.company_additional_selection_criteria.get(company, "")
                
                # ì‚¬ìš©ì ìˆ˜ì • ê¸°ì¤€ + í•´ë‹¹ íšŒì‚¬ íŠ¹í™” ê¸°ì¤€ ê²°í•©
                enhanced_exclusion_criteria = base_exclusion + company_additional_exclusion
                enhanced_duplicate_handling = base_duplicate + company_additional_duplicate  
                enhanced_selection_criteria = base_selection + company_additional_selection
            
            # initial_state ì„¤ì • ë¶€ë¶„ ì§ì „ì— valid_press_dictë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ëŠ” ì½”ë“œ ì¶”ê°€
            # í…ìŠ¤íŠ¸ ì—ì–´ë¦¬ì–´ì˜ ë‚´ìš©ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            valid_press_config = {}
            try:
                # ë¬¸ìì—´ì—ì„œ ë”•ì…”ë„ˆë¦¬ íŒŒì‹±
                lines = valid_press_dict.strip().split('\n')
                for line in lines:
                    line = line.strip()
                    if line and ': ' in line:
                        press_name, aliases_str = line.split(':', 1)
                        try:
                            # ë¬¸ìì—´ í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                            aliases = eval(aliases_str.strip())
                            valid_press_config[press_name.strip()] = aliases
                            print(f"[DEBUG] Valid press íŒŒì‹± ì„±ê³µ: {press_name.strip()} -> {aliases}")
                        except Exception as e:
                            print(f"[DEBUG] Valid press íŒŒì‹± ì‹¤íŒ¨: {line}, ì˜¤ë¥˜: {str(e)}")
            except Exception as e:
                print(f"[DEBUG] Valid press ì „ì²´ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©
                valid_press_config = {}
            
            print(f"[DEBUG] íŒŒì‹±ëœ valid_press_dict: {valid_press_config}")
            
            # ì¶”ê°€ ì–¸ë¡ ì‚¬ë„ íŒŒì‹±
            additional_press_config = {}
            try:
                # ë¬¸ìì—´ì—ì„œ ë”•ì…”ë„ˆë¦¬ íŒŒì‹±
                lines = additional_press_dict.strip().split('\n')
                for line in lines:
                    line = line.strip()
                    if line and ': ' in line:
                        press_name, aliases_str = line.split(':', 1)
                        try:
                            # ë¬¸ìì—´ í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                            aliases = eval(aliases_str.strip())
                            additional_press_config[press_name.strip()] = aliases
                            print(f"[DEBUG] Additional press íŒŒì‹± ì„±ê³µ: {press_name.strip()} -> {aliases}")
                        except Exception as e:
                            print(f"[DEBUG] Additional press íŒŒì‹± ì‹¤íŒ¨: {line}, ì˜¤ë¥˜: {str(e)}")
            except Exception as e:
                print(f"[DEBUG] Additional press ì „ì²´ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©
                additional_press_config = {}
            
            print(f"[DEBUG] íŒŒì‹±ëœ additional_press_dict: {additional_press_config}")
            
            # ê° í‚¤ì›Œë“œë³„ ìƒíƒœ ì´ˆê¸°í™”
            initial_state = {
                "news_data": [], 
                "filtered_news": [], 
                "analysis": "", 
                "keyword": company_keywords,  # íšŒì‚¬ë³„ í™•ì¥ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
                "model": selected_model,
                "excluded_news": [],
                "borderline_news": [],
                "retained_news": [],
                "grouped_news": [],
                "final_selection": [],
                # íšŒì‚¬ë³„ enhanced ê¸°ì¤€ë“¤ ì ìš©
                "exclusion_criteria": enhanced_exclusion_criteria,
                "duplicate_handling": enhanced_duplicate_handling,
                "selection_criteria": enhanced_selection_criteria,
                "system_prompt_1": scope_system_prompt_1,
                "user_prompt_1": "",
                "llm_response_1": "",
                "system_prompt_2": scope_system_prompt_2,
                "user_prompt_2": "",
                "llm_response_2": "",
                "system_prompt_3": scope_system_prompt_3,
                "user_prompt_3": "",
                "llm_response_3": "",
                "not_selected_news": [],
                "original_news_data": [],
                # ì–¸ë¡ ì‚¬ ì„¤ì • ì¶”ê°€ (íŒŒì‹±ëœ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©)
                "valid_press_dict": valid_press_config,
                # ì¶”ê°€ ì–¸ë¡ ì‚¬ ì„¤ì • ì¶”ê°€
                "additional_press_dict": additional_press_config,
                # ë‚ ì§œ í•„í„° ì •ë³´ ì¶”ê°€
                "start_datetime": datetime.combine(start_date, start_time, KST),
                "end_datetime": datetime.combine(end_date, end_time, KST)
                #"start_datetime": start_datetime,
                #"end_datetime": end_datetime
            }
            
            
            print(f"[DEBUG] start_datetime: {datetime.combine(start_date, start_time)}")
            print(f"[DEBUG] end_datetime: {datetime.combine(end_date, end_time)}")
            
            # 1ë‹¨ê³„: ë‰´ìŠ¤ ìˆ˜ì§‘
            st.write("1ë‹¨ê³„: ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
            state_after_collection = collect_news(initial_state)
            
            # 2ë‹¨ê³„: ìœ íš¨ ì–¸ë¡ ì‚¬ í•„í„°ë§ (ê¸€ë¡œë²Œ ë‰´ìŠ¤ë¥¼ ìœ„í•´ ê±´ë„ˆëœ€)
            st.write("2ë‹¨ê³„: ë‚ ì§œ í•„í„°ë§ ì¤‘...")
            state_after_press_filter = state_after_collection  # í•„í„°ë§ ì—†ì´ ê·¸ëŒ€ë¡œ ì „ë‹¬
            
            # 3ë‹¨ê³„: ì œì™¸ íŒë‹¨
            st.write("3ë‹¨ê³„: ì œì™¸ íŒë‹¨ ì¤‘...")
            state_after_exclusion = filter_excluded_news(state_after_press_filter)
            
            # 4ë‹¨ê³„: ê·¸ë£¹í•‘
            st.write("4ë‹¨ê³„: ê·¸ë£¹í•‘ ì¤‘...")
            state_after_grouping = group_and_select_news(state_after_exclusion)
            
            # 5ë‹¨ê³„: ì¤‘ìš”ë„ í‰ê°€
            st.write("5ë‹¨ê³„: ì¤‘ìš”ë„ í‰ê°€ ì¤‘...")
            final_state = evaluate_importance(state_after_grouping)
            
            # 6ë‹¨ê³„: ê¸°ì‚¬ ì›ë¬¸ ìš”ì•½ (ì˜µì…˜)
            if enable_article_summary and final_state.get("final_selection"):
                st.write("6ë‹¨ê³„: ì„ ì •ëœ ê¸°ì‚¬ ì›ë¬¸ ìš”ì•½ ì¤‘...")
                final_state = summarize_selected_articles(final_state)

            # 6ë‹¨ê³„: 0ê°œ ì„ íƒ ì‹œ ì¬í‰ê°€ (ê°œì„ ëœ ì½”ë“œ)
            if len(final_state["final_selection"]) == 0:
                st.write("6ë‹¨ê³„: ì„ íƒëœ ë‰´ìŠ¤ê°€ ì—†ì–´ ì¬í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
                
                # ì¶”ê°€ ì–¸ë¡ ì‚¬ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° (ì´ë¯¸ íŒŒì‹±ëœ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©)
                additional_press = additional_press_config
                
                # ê¸°ì¡´ ìœ íš¨ ì–¸ë¡ ì‚¬ì— ì¶”ê°€ ì–¸ë¡ ì‚¬ ë³‘í•© (ë”•ì…”ë„ˆë¦¬ ë³‘í•©)
                expanded_valid_press_dict = {**valid_press_config, **additional_press}
                
                # ì¶”ê°€ ì–¸ë¡ ì‚¬ë¡œ í•„í„°ë§í•œ ë‰´ìŠ¤ ì €ì¥ (ê¸°ì¡´ ë‰´ìŠ¤ì™€ êµ¬ë¶„)
                additional_valid_news = []
                
                # í™•ì¥ëœ ì–¸ë¡ ì‚¬ ëª©ë¡ìœ¼ë¡œ ì›ë³¸ ë‰´ìŠ¤ ì¬í•„í„°ë§
                try:
                    # í˜„ì¬ í•„í„°ë§ëœ ìœ íš¨ ì–¸ë¡ ì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘
                    current_news_data = final_state.get("news_data", [])
                    
                    # ì›ë³¸ ë‰´ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    original_news_data = final_state.get("original_news_data", [])
                    
                    if expanded_valid_press_dict:
                        # í™•ì¥ëœ ì–¸ë¡ ì‚¬ ëª©ë¡ìœ¼ë¡œ ì›ë³¸ ë‰´ìŠ¤ ì¬í•„í„°ë§
                        for news in original_news_data:
                            # ì´ë¯¸ í•„í„°ë§ëœ ë‰´ìŠ¤ëŠ” ì œì™¸
                            if any(existing_news.get('url') == news.get('url') for existing_news in current_news_data):
                                continue
                                
                            press = news.get("press", "").lower()
                            url = news.get("url", "").lower()
                            
                            # ì¶”ê°€ëœ ì–¸ë¡ ì‚¬ ê¸°ì¤€ìœ¼ë¡œë§Œ í•„í„°ë§
                            is_valid = False
                            for main_press, aliases in expanded_valid_press_dict.items():
                                domain = urlparse(url).netloc.lower()
                                # ë” ìœ ì—°í•œ ë§¤ì¹­ ì ìš©
                                if any(alias.lower() in press or press in alias.lower() for alias in aliases) or \
                                   any(alias.lower() in domain or domain in alias.lower() for alias in aliases):
                                    is_valid = True
                                    break
                            
                            if is_valid:
                                # ìƒˆ ì–¸ë¡ ì‚¬ í•„í„°ë§ëœ ë‰´ìŠ¤ì„ì„ í‘œì‹œ
                                additional_valid_news.append(news)
                    
                    # ì¶”ê°€ ìœ íš¨ ë‰´ìŠ¤ê°€ ìˆìœ¼ë©´ ê¸°ì¡´ news_dataì— ì¶”ê°€
                    if additional_valid_news:
                        st.success(f"ì¶”ê°€ ì–¸ë¡ ì‚¬ ê¸°ì¤€ìœ¼ë¡œ {len(additional_valid_news)}ê°œì˜ ë‰´ìŠ¤ê°€ ì¶”ê°€ë¡œ í•„í„°ë§ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        
                        # ê¸°ì¡´ ë‰´ìŠ¤ ë°ì´í„°ì™€ ë³‘í•©
                        combined_news = current_news_data + additional_valid_news
                        reevaluation_state = final_state.copy()
                        reevaluation_state["news_data"] = combined_news
                        
                        # ì¶”ê°€ëœ ë‰´ìŠ¤ë“¤ì— ëŒ€í•œ ì œì™¸/ìœ ì§€ íŒë‹¨ ì¬ì‹¤í–‰
                        reevaluation_state = filter_excluded_news(reevaluation_state)
                        
                        # ê·¸ë£¹í•‘ ì¬ì‹¤í–‰
                        reevaluation_state = group_and_select_news(reevaluation_state)
                    else:
                        # ì¶”ê°€ ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ì›ë˜ ìƒíƒœ ë³µì‚¬
                        reevaluation_state = final_state.copy()
                        combined_news = current_news_data
                except Exception as e:
                    st.warning(f"ì¶”ê°€ ì–¸ë¡ ì‚¬ í•„í„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    reevaluation_state = final_state.copy()
                    combined_news = final_state.get("news_data", [])
                
                # í™•ì¥ëœ ìœ íš¨ ì–¸ë¡ ì‚¬ ëª©ë¡ ë¬¸ìì—´ë¡œ ë³€í™˜ (í”„ë¡¬í”„íŠ¸ìš©)
                expanded_valid_press_str = "ìœ íš¨ ì–¸ë¡ ì‚¬ ëª©ë¡:\n"
                for press, aliases in expanded_valid_press_dict.items():
                    expanded_valid_press_str += f"  * {press}: {aliases}\n"
                
                # ì¬í‰ê°€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°œì„  - ëª¨ë“  ë‰´ìŠ¤ ë°ì´í„° í¬í•¨
                reevaluation_system_prompt = f"""
                ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ì˜ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í˜„ì¬ ì„ ì •ëœ ë‰´ìŠ¤ê°€ ì—†ì–´ ì¬í‰ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤.
                ì•„ë˜ 4ê°€ì§€ ë°©í–¥ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ì¬ê²€í† í•˜ì„¸ìš”:

                1. ì–¸ë¡ ì‚¬ í•„í„°ë§ ê¸°ì¤€ ì™„í™”:
                - ê¸°ì¡´ ìœ íš¨ ì–¸ë¡ ì‚¬ ëª©ë¡ ì™¸ì—ë„ ë‹¤ìŒ ì–¸ë¡ ì‚¬ì˜ ê¸°ì‚¬ë¥¼ í¬í•¨í•˜ì—¬ í‰ê°€í•©ë‹ˆë‹¤:
                  * ì² ê°•ê¸ˆì†ì‹ ë¬¸: ì‚°ì—… ì „ë¬¸ì§€ë¡œ ê¸ˆì†/ì² ê°• ì—…ê³„ ì†Œì‹ì— íŠ¹í™”ë¨
                  * ì—ë„ˆì§€ì‹ ë¬¸: ì—ë„ˆì§€ ì‚°ì—… ì „ë¬¸ ë§¤ì²´ë¡œ ê´€ë ¨ ê¸°ì—… ë¶„ì„ì— ìœ ìš©í•¨
                  * ì´ì½”ë…¸ë¯¹ë°ì¼ë¦¬: ê²½ì œ ì „ë¬¸ì§€ë¡œ ì¶”ê°€ì ì¸ ì‹œê° ì œê³µ

                2. ì œì™¸ ì¡°ê±´ ì¬í‰ê°€:
                - ì œì™¸ ê¸°ì¤€ì„ ìœ ì—°í•˜ê²Œ ì ìš©í•˜ì—¬, íšŒê³„ë²•ì¸ì˜ ê´€ì ì—ì„œ ì¬ë¬´ì  ê´€ì ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥í•œ ê¸°ì‚¬ë“¤ì„ ë³´ë¥˜ë¡œ ë¶„ë¥˜
                - íŠ¹íˆ ê¸°ì—…ì˜ ì¬ì • í˜¹ì€ ì „ëµì  ë³€ë™ê³¼ ì—°ê´€ëœ ê¸°ì‚¬ë¥¼ ë³´ë¥˜ë¡œ ì „í™˜

                3. ì¤‘ë³µ ì œê±° ì¬í‰ê°€:
                - ì¤‘ë³µ ê¸°ì‚¬ ì¤‘ì—ì„œë„ ì–¸ë¡ ì‚¬ì˜ ì‹ ë¢°ë„ë‚˜ ê¸°ì‚¬ ë‚´ìš©ì„ ì¶”ê°€ë¡œ ê³ ë ¤í•˜ì—¬ ê°€ëŠ¥í•œ ê²½ìš° ì¶”ê°€ì ìœ¼ë¡œ ì„ íƒ
                - ì¬ë¬´ì /ì „ëµì  ê´€ì ì—ì„œ ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê¸°ì‚¬ ìš°ì„  ì„ íƒ

                4. ì¤‘ìš”ë„ ì¬í‰ê°€:
                - ì„ íƒ ê¸°ì¤€ì„ ì¼ë¶€ ì¶©ì¡±í•˜ì§€ ì•ŠëŠ” ê¸°ì‚¬ì¼ì§€ë¼ë„ ê¸°ì—…ëª…ê³¼ ê´€ë ¨ëœ ì¬ì •ì  ë˜ëŠ” ì „ëµì  ë³€ë™ì— ëŒ€í•´ì„œëŠ” ì¤‘ìš”ë„ë¥¼ 'ì¤‘'ìœ¼ë¡œ í‰ê°€
                - í•„ìš”í•˜ë‹¤ë©´ ì¤‘ìš”ë„ 'í•˜'ë„ ê³ ë ¤í•˜ì—¬ ìµœì†Œ 2ê°œì˜ ê¸°ì‚¬ë¥¼ ì„ ì •

                [í™•ì¥ëœ ìœ íš¨ ì–¸ë¡ ì‚¬ ëª©ë¡]
                {expanded_valid_press_str}

                [ê¸°ì¡´ ì œì™¸ ê¸°ì¤€]
                {enhanced_exclusion_criteria}

                [ê¸°ì¡´ ì¤‘ë³µ ì²˜ë¦¬ ê¸°ì¤€]
                {enhanced_duplicate_handling}

                [ê¸°ì¡´ ì„ íƒ ê¸°ì¤€]
                {enhanced_selection_criteria}

                [ì „ì²´ ë‰´ìŠ¤ ëª©ë¡]
                """
                
                # ëª¨ë“  ë‰´ìŠ¤ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í†µí•© (JSON í˜•ì‹ìœ¼ë¡œ)
                all_news_json = []
                for i, news in enumerate(combined_news):
                    all_news_json.append({
                        "index": i+1,
                        "title": news.get('content', 'ì œëª© ì—†ìŒ'),
                        "url": news.get('url', ''),
                        "date": news.get('date', ''),
                        "press": news.get('press', '')
                    })
                
                # í”„ë¡¬í”„íŠ¸ì— í†µí•©ëœ ë‰´ìŠ¤ ëª©ë¡ ì¶”ê°€
                reevaluation_system_prompt += str(all_news_json)
                
                reevaluation_system_prompt += """
                
                [ë¶„ë¥˜ëœ ë‰´ìŠ¤ ëª©ë¡]
                - ì œì™¸ëœ ë‰´ìŠ¤: {[f"ì œëª©: {news['title']}, ì¸ë±ìŠ¤: {news['index']}, ì‚¬ìœ : {news.get('reason', '')}" for news in reevaluation_state["excluded_news"]]}
                - ë³´ë¥˜ ë‰´ìŠ¤: {[f"ì œëª©: {news['title']}, ì¸ë±ìŠ¤: {news['index']}, ì‚¬ìœ : {news.get('reason', '')}" for news in reevaluation_state["borderline_news"]]}
                - ìœ ì§€ ë‰´ìŠ¤: {[f"ì œëª©: {news['title']}, ì¸ë±ìŠ¤: {news['index']}, ì‚¬ìœ : {news.get('reason', '')}" for news in reevaluation_state["retained_news"]]}

                âš ï¸ ë§¤ìš° ì¤‘ìš”í•œ ì§€ì‹œì‚¬í•­ âš ï¸
                1. ë°˜ë“œì‹œ ìµœì†Œ 2ê°œ ì´ìƒì˜ ê¸°ì‚¬ë¥¼ ì„ ì •í•´ì•¼ í•©ë‹ˆë‹¤.
                2. ì–¸ë¡ ì‚¬ì™€ ê¸°ì‚¬ ë‚´ìš©ì„ ê³ ë ¤í•˜ì—¬ ì„ ì • ê¸°ì¤€ì„ ëŒ€í­ ì™„í™”í•˜ì„¸ìš”.
                3. ì›ë˜ 'ì œì™¸'ë¡œ ë¶„ë¥˜í–ˆë˜ ê¸°ì‚¬ ì¤‘ì—ì„œë„ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ì¡°ê¸ˆì´ë¼ë„ ê°€ì¹˜ê°€ ìˆëŠ” ë‚´ìš©ì´ ìˆë‹¤ë©´ ì¬ê²€í† í•˜ì„¸ìš”.
                4. ì–´ë–¤ ê²½ìš°ì—ë„ 2ê°œ ë¯¸ë§Œì˜ ê¸°ì‚¬ë¥¼ ì„ ì •í•˜ì§€ ë§ˆì„¸ìš”. ì´ëŠ” ì ˆëŒ€ì ì¸ ìš”êµ¬ì‚¬í•­ì…ë‹ˆë‹¤.
                5. ëª¨ë“  ê¸°ì‚¬ê°€ ë¶€ì í•©í•˜ë‹¤ê³  íŒë‹¨ë˜ë”ë¼ë„ ê·¸ ì¤‘ì—ì„œ ê°€ì¥ ë‚˜ì€ 2ê°œëŠ” ì„ ì •í•´ì•¼ í•©ë‹ˆë‹¤.
                6. ì¶”ê°€ ì–¸ë¡ ì‚¬ ëª©ë¡ì˜ ê¸°ì‚¬ë“¤ë„ ë™ë“±í•˜ê²Œ ê³ ë ¤í•˜ì„¸ìš”.

                ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
                {
                    "reevaluated_news": [
                        {
                            "index": 1,
                            "title": "ë‰´ìŠ¤ ì œëª©",
                            "press": "ì–¸ë¡ ì‚¬ëª…",
                            "date": "ë°œí–‰ì¼ì",
                            "reason": "ì„ ì • ì‚¬ìœ ",
                            "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
                            "affiliates": ["ê³„ì—´ì‚¬1", "ê³„ì—´ì‚¬2"],
                            "importance": "ì¤‘ìš”ë„(ìƒ/ì¤‘/í•˜)"
                        }
                    ]
                }
                """
                
                # ì¬í‰ê°€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ì—…ë°ì´íŠ¸
                reevaluation_state["system_prompt_3"] = reevaluation_system_prompt
                
                # ì¬í‰ê°€ ì‹¤í–‰ (evaluate_importance í•¨ìˆ˜ ì¬ì‚¬ìš©)
                st.write("- ì œì™¸/ì¤‘ë³µ/ì¤‘ìš”ë„ í†µí•© ì¬í‰ê°€ ì¤‘...")
                reevaluation_result = evaluate_importance(reevaluation_state)
                
                # ì¬í‰ê°€ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸
                if "final_selection" in reevaluation_result and reevaluation_result["final_selection"]:
                    final_state["final_selection"] = reevaluation_result["final_selection"]
                    # ì¬í‰ê°€ ê²°ê³¼ì„ì„ í‘œì‹œí•˜ê¸° ìœ„í•œ í•„ë“œ ì¶”ê°€
                    final_state["is_reevaluated"] = True
                    st.success(f"ì¬í‰ê°€ í›„ {len(final_state['final_selection'])}ê°œì˜ ë‰´ìŠ¤ê°€ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    # ê·¸ë˜ë„ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€ë§Œ í‘œì‹œ
                    st.error("ì¬í‰ê°€ í›„ì—ë„ ì„ ì •í•  ìˆ˜ ìˆëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

            # í‚¤ì›Œë“œë³„ ë¶„ì„ ê²°ê³¼ ì €ì¥
            all_results[company] = final_state["final_selection"]
            
            # í‚¤ì›Œë“œ êµ¬ë¶„ì„  ì¶”ê°€
            st.markdown("---")
            
            # í‚¤ì›Œë“œë³„ ì„¹ì…˜ êµ¬ë¶„
            st.markdown(f"## ğŸ“Š {company} ë¶„ì„ ê²°ê³¼")
            
            # ì „ì²´ ë‰´ìŠ¤ í‘œì‹œ (í•„í„°ë§ ì „)
            with st.expander(f"ğŸ“° '{company}' ê´€ë ¨ ì „ì²´ ë‰´ìŠ¤ (í•„í„°ë§ ì „)"):
                for i, news in enumerate(final_state.get("original_news_data", []), 1):
                    date_str = news.get('date', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')
                    url = news.get('url', 'URL ì •ë³´ ì—†ìŒ')
                    press = news.get('press', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    st.markdown(f"""
                    <div class="news-card">
                        <div class="news-title">{i}. {news['content']}</div>
                        <div class="news-meta">ğŸ“° {press}</div>
                        <div class="news-date">ğŸ“… {date_str}</div>
                        <div class="news-url">ğŸ”— <a href="{url}" target="_blank">{url}</a></div>
                    </div>
                    """, unsafe_allow_html=True)
            
            # ìœ íš¨ ì–¸ë¡ ì‚¬ í•„í„°ë§ëœ ë‰´ìŠ¤ í‘œì‹œ
            with st.expander(f"ğŸ“° '{company}' ê´€ë ¨ ìœ íš¨ ì–¸ë¡ ì‚¬ ë‰´ìŠ¤"):
                for i, news in enumerate(final_state["news_data"]):
                    date_str = news.get('date', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')
                    url = news.get('url', 'URL ì •ë³´ ì—†ìŒ')
                    press = news.get('press', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    st.markdown(f"""
                    <div class="news-card">
                        <div class="news-title">{i+1}. {news['content']}</div>
                        <div class="news-meta">ğŸ“° {press}</div>
                        <div class="news-date">ğŸ“… {date_str}</div>
                        <div class="news-url">ğŸ”— <a href="{url}" target="_blank">{url}</a></div>
                    </div>
                    """, unsafe_allow_html=True)
            
            # 2ë‹¨ê³„: ìœ íš¨ ì–¸ë¡ ì‚¬ í•„í„°ë§ ê²°ê³¼ í‘œì‹œ
            st.markdown("<div class='subtitle'>ğŸ” 2ë‹¨ê³„: ìœ íš¨ ì–¸ë¡ ì‚¬ í•„í„°ë§ ê²°ê³¼</div>", unsafe_allow_html=True)
            st.markdown(f"ìœ íš¨ ì–¸ë¡ ì‚¬ ë‰´ìŠ¤: {len(final_state['news_data'])}ê°œ")
            
            # 3ë‹¨ê³„: ì œì™¸/ë³´ë¥˜/ìœ ì§€ ë‰´ìŠ¤ í‘œì‹œ
            st.markdown("<div class='subtitle'>ğŸ” 3ë‹¨ê³„: ë‰´ìŠ¤ ë¶„ë¥˜ ê²°ê³¼</div>", unsafe_allow_html=True)
            
            # ì œì™¸ëœ ë‰´ìŠ¤
            with st.expander("âŒ ì œì™¸ëœ ë‰´ìŠ¤"):
                for news in final_state["excluded_news"]:
                    st.markdown(f"<div class='excluded-news'>[{news['index']}] {news['title']}<br/>â”” {news['reason']}</div>", unsafe_allow_html=True)
            
            # ë³´ë¥˜ ë‰´ìŠ¤
            with st.expander("âš ï¸ ë³´ë¥˜ ë‰´ìŠ¤"):
                for news in final_state["borderline_news"]:
                    st.markdown(f"<div class='excluded-news'>[{news['index']}] {news['title']}<br/>â”” {news['reason']}</div>", unsafe_allow_html=True)
            
            # ìœ ì§€ ë‰´ìŠ¤
            with st.expander("âœ… ìœ ì§€ ë‰´ìŠ¤"):
                for news in final_state["retained_news"]:
                    st.markdown(f"<div class='excluded-news'>[{news['index']}] {news['title']}<br/>â”” {news['reason']}</div>", unsafe_allow_html=True)
            
            # 4ë‹¨ê³„: ê·¸ë£¹í•‘ ê²°ê³¼ í‘œì‹œ
            st.markdown("<div class='subtitle'>ğŸ” 4ë‹¨ê³„: ë‰´ìŠ¤ ê·¸ë£¹í•‘ ê²°ê³¼</div>", unsafe_allow_html=True)
            
            with st.expander("ğŸ“‹ ê·¸ë£¹í•‘ ê²°ê³¼ ë³´ê¸°"):
                for group in final_state["grouped_news"]:
                    st.markdown(f"""
                    <div class="analysis-section">
                        <h4>ê·¸ë£¹ {group['indices']}</h4>
                        <p>ì„ íƒëœ ê¸°ì‚¬: {group['selected_index']}</p>
                        <p>ì„ ì • ì´ìœ : {group['reason']}</p>
                    </div>
                    """, unsafe_allow_html=True)
            
            # 5ë‹¨ê³„: ìµœì¢… ì„ íƒ ê²°ê³¼ í‘œì‹œ
            st.markdown("<div class='subtitle'>ğŸ” 5ë‹¨ê³„: ìµœì¢… ì„ íƒ ê²°ê³¼</div>", unsafe_allow_html=True)
            
            # ì¬í‰ê°€ ì—¬ë¶€ í™•ì¸ (is_reevaluated í•„ë“œ ìˆìœ¼ë©´ ì¬í‰ê°€ëœ ê²ƒ)
            was_reevaluated = final_state.get("is_reevaluated", False)
            
            # ì¬í‰ê°€ ì—¬ë¶€ì— ë”°ë¼ ë©”ì‹œì§€ì™€ ìŠ¤íƒ€ì¼ ë³€ê²½
            if was_reevaluated:
                # ì¬í‰ê°€ê°€ ìˆ˜í–‰ëœ ê²½ìš° 6ë‹¨ê³„ í‘œì‹œ
                st.warning("5ë‹¨ê³„ì—ì„œ ì„ ì •ëœ ë‰´ìŠ¤ê°€ ì—†ì–´ 6ë‹¨ê³„ ì¬í‰ê°€ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.")
                st.markdown("<div class='subtitle'>ğŸ” 6ë‹¨ê³„: ì¬í‰ê°€ ê²°ê³¼</div>", unsafe_allow_html=True)
                st.markdown("### ğŸ“° ì¬í‰ê°€ í›„ ì„ ì •ëœ ë‰´ìŠ¤")
                # ì¬í‰ê°€ ìŠ¤íƒ€ì¼ ì ìš©
                news_style = "border-left: 4px solid #FFA500; background-color: #FFF8DC;"
                reason_prefix = "<span style=\"color: #FFA500; font-weight: bold;\">ì¬í‰ê°€ í›„</span> ì„ ë³„ ì´ìœ : "
            else:
                # ì •ìƒì ìœ¼ë¡œ 5ë‹¨ê³„ì—ì„œ ì„ ì •ëœ ê²½ìš°
                st.markdown("### ğŸ“° ìµœì¢… ì„ ì •ëœ ë‰´ìŠ¤")  
                # ì¼ë°˜ ìŠ¤íƒ€ì¼ ì ìš©
                news_style = ""
                reason_prefix = "ì„ ë³„ ì´ìœ : "
            
            # ìµœì¢… ì„ ì •ëœ ë‰´ìŠ¤ í‘œì‹œ
            for news in final_state["final_selection"]:
                # ë‚ ì§œ í˜•ì‹ ë³€í™˜
                
                date_str = format_date(news.get('date', ''))
                
                try:
                    # YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ê°€ì •
                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                    formatted_date = date_obj.strftime('%m/%d')
                except Exception as e:
                    try:
                        # GMT í˜•ì‹ ì‹œë„
                        date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
                        formatted_date = date_obj.strftime('%m/%d')
                    except Exception as e:
                        formatted_date = date_str if date_str else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'

                url = news.get('url', 'URL ì •ë³´ ì—†ìŒ')
                press = news.get('press', 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ')
                
                # AI ìš”ì•½ í…ìŠ¤íŠ¸ ì¤€ë¹„ (HTML íƒœê·¸ ì™„ì „ ì œê±°)
                clean_summary = None
                if news.get('ai_summary'):
                    clean_summary = _clean_html_for_display(news['ai_summary'])
                
                # ë‰´ìŠ¤ ì •ë³´ í‘œì‹œ
                st.markdown(f"""
                    <div class="selected-news" style="{news_style}">
                        <div class="news-title-large">{news['title']} ({formatted_date})</div>
                        <div class="news-url">ğŸ”— <a href="{url}" target="_blank">{url}</a></div>
                        <div class="selection-reason">
                            â€¢ {reason_prefix}{news['reason']}
                        </div>
                        <div class="news-summary">
                            â€¢ í‚¤ì›Œë“œ: {', '.join(news['keywords'])} | ê´€ë ¨ ê³„ì—´ì‚¬: {', '.join(news['affiliates'])} | ì–¸ë¡ ì‚¬: {press}
                        </div>
                        {_format_ai_summary_for_box(clean_summary, news.get('extraction_success', False))}
                """, unsafe_allow_html=True)
                
                # êµ¬ë¶„ì„  ì¶”ê°€
                st.markdown("---")
            
            # ì„ ì •ë˜ì§€ ì•Šì€ ë‰´ìŠ¤ í‘œì‹œ
            if final_state.get("not_selected_news"):
                with st.expander("âŒ ì„ ì •ë˜ì§€ ì•Šì€ ë‰´ìŠ¤"):
                    for news in final_state["not_selected_news"]:
                        st.markdown(f"""
                        <div class="not-selected-news">
                            <div class="news-title">{news['index']}. {news['title']}</div>
                            <div class="importance-low">ğŸ’¡ ì¤‘ìš”ë„: {news['importance']}</div>
                            <div class="not-selected-reason">âŒ ë¯¸ì„ ì • ì‚¬ìœ : {news['reason']}</div>
                        </div>
                        """, unsafe_allow_html=True)
            
            # ë””ë²„ê·¸ ì •ë³´
            with st.expander("ë””ë²„ê·¸ ì •ë³´"):
                st.markdown("### 1ë‹¨ê³„: ì œì™¸ íŒë‹¨")
                st.markdown("#### ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸")
                st.text(final_state.get("system_prompt_1", "ì—†ìŒ"))
                st.markdown("#### ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸")
                st.text(final_state.get("user_prompt_1", "ì—†ìŒ"))
                st.markdown("#### LLM ì‘ë‹µ")
                st.text(final_state.get("llm_response_1", "ì—†ìŒ"))
                
                st.markdown("### 2ë‹¨ê³„: ê·¸ë£¹í•‘")
                st.markdown("#### ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸")
                st.text(final_state.get("system_prompt_2", "ì—†ìŒ"))
                st.markdown("#### ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸")
                st.text(final_state.get("user_prompt_2", "ì—†ìŒ"))
                st.markdown("#### LLM ì‘ë‹µ")
                st.text(final_state.get("llm_response_2", "ì—†ìŒ"))
                
                st.markdown("### 3ë‹¨ê³„: ì¤‘ìš”ë„ í‰ê°€")
                st.markdown("#### ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸")
                st.text(final_state.get("system_prompt_3", "ì—†ìŒ"))
                st.markdown("#### ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸")
                st.text(final_state.get("user_prompt_3", "ì—†ìŒ"))
                st.markdown("#### LLM ì‘ë‹µ")
                st.text(final_state.get("llm_response_3", "ì—†ìŒ"))
                
                # 6ë‹¨ê³„: ì¬í‰ê°€ ì •ë³´ ì¶”ê°€
                if final_state.get("is_reevaluated", False):
                    st.markdown("### 4ë‹¨ê³„: ì¬í‰ê°€")
                    st.markdown("#### ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸")
                    # ì‹¤ì œ ì‚¬ìš©ëœ ì¬í‰ê°€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
                    st.text(reevaluation_state.get("system_prompt_3", "ì—†ìŒ") if 'reevaluation_state' in locals() else "ì¬í‰ê°€ í”„ë¡¬í”„íŠ¸ ì •ë³´ ì—†ìŒ")
                    st.markdown("#### ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸")
                    st.text(reevaluation_state.get("user_prompt_3", "ì—†ìŒ") if 'reevaluation_state' in locals() else "ì¬í‰ê°€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì •ë³´ ì—†ìŒ")
                    st.markdown("#### LLM ì‘ë‹µ")
                    st.text(reevaluation_state.get("llm_response_3", "ì—†ìŒ") if 'reevaluation_state' in locals() else "ì¬í‰ê°€ LLM ì‘ë‹µ ì •ë³´ ì—†ìŒ")
            
            # ì´ë©”ì¼ ë‚´ìš© ì¶”ê°€
            email_content += f"{i}. {company}\n"
            for news in final_state["final_selection"]:
                # ë‚ ì§œ í˜•ì‹ ë³€í™˜
                date_str = news.get('date', '')
                try:
                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                    formatted_date = date_obj.strftime('%m/%d')
                except Exception as e:
                    try:
                        date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
                        formatted_date = date_obj.strftime('%m/%d')
                    except Exception as e:
                        formatted_date = date_str if date_str else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'
                
                url = news.get('url', '')
                email_content += f"  - {news['title']} ({formatted_date}) {url}\n"
            email_content += "\n"
            
            # í‚¤ì›Œë“œ êµ¬ë¶„ì„  ì¶”ê°€
            st.markdown("---")

    # ëª¨ë“  í‚¤ì›Œë“œ ë¶„ì„ì´ ëë‚œ í›„ HTML ì´ë©”ì¼ ìƒì„±
    st.markdown("---")
    st.markdown("### ğŸ“§ ì´ë©”ì¼ìš© HTML ìš”ì•½")
    st.markdown("ì•„ë˜ HTMLì„ ë³µì‚¬í•˜ì—¬ ì´ë©”ì¼ë¡œ ì „ì†¡í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ëª¨ë“  í‚¤ì›Œë“œì˜ ìµœì¢… ì„ ì • ê¸°ì‚¬ë“¤ì„ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í†µí•©
    all_final_news = []
    for company, results in all_results.items():
        for news in results:
            news['source_keyword'] = company
            all_final_news.append(news)
    
    if all_final_news:
        with st.spinner("ì„ ì •ëœ ê¸°ì‚¬ë“¤ì˜ ìƒì„¸ ìš”ì•½ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
            # ì›¹ ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
            from web_scraper import HybridNewsWebScraper
            scraper = HybridNewsWebScraper(
                openai_api_key=os.getenv('OPENAI_API_KEY'),
                enable_ai_fallback=True
            )
            
            # HTML ì´ë©”ì¼ ë‚´ìš© ìƒì„±
            html_content = """
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; color: #333; }
        .header { background-color: #d04a02; color: white; padding: 20px; text-align: center; }
        .article { border: 1px solid #ddd; margin: 20px 0; padding: 20px; border-radius: 8px; }
        .article-title { font-size: 1.3em; font-weight: bold; color: #d04a02; margin-bottom: 10px; }
        .article-meta { color: #666; font-size: 0.9em; margin-bottom: 15px; }
        .korean-title { font-size: 1.2em; font-weight: bold; color: #333; margin: 15px 0 10px 0; }
        .oneline-summary { background-color: #f0f8ff; padding: 12px; border-radius: 6px; margin: 15px 0; border-left: 4px solid #0077b6; }
        .details { margin: 15px 0; }
        .details li { margin-bottom: 8px; line-height: 1.4; }
        .original-url { margin-top: 15px; }
        .original-url a { color: #0077b6; text-decoration: none; }
        .original-url a:hover { text-decoration: underline; }
        .footer { background-color: #f8f9fa; padding: 15px; text-align: center; color: #666; margin-top: 30px; }
    </style>
</head>
<body>
    <div class="header">
        <h1>PwC ë‰´ìŠ¤ ë¶„ì„ ë³´ê³ ì„œ</h1>
        <p>ìƒì„±ì¼: """ + datetime.now().strftime("%Yë…„ %mì›” %dì¼ %H:%M") + """</p>
    </div>
"""
            
            # ê° ê¸°ì‚¬ë³„ë¡œ ìƒì„¸ ì •ë³´ ì¶”ê°€
            for i, news in enumerate(all_final_news, 1):
                url = news.get('url', '')
                title = news.get('title', 'ì œëª© ì—†ìŒ')
                press = news.get('press', 'ì•Œ ìˆ˜ ì—†ìŒ')
                date_str = news.get('date', '')
                source_keyword = news.get('source_keyword', '')
                reason = news.get('reason', '')
                
            # ë‚ ì§œ í˜•ì‹ ë³€í™˜
            try:
                if 'GMT' in date_str:
                        date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
                        formatted_date = date_obj.strftime('%Y-%m-%d')
                else:
                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                        formatted_date = date_str
            except:
                        formatted_date = date_str if date_str else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'
                
                # Google News URL ë””ì½”ë”©
                original_url = url
                if 'news.google.com' in url:
                    decoded_url = scraper._resolve_google_news_url_simple(url, timeout=10)
                    if decoded_url:
                        original_url = decoded_url
                
                # ê¸°ì‚¬ ì›ë¬¸ ìš”ì•½ ì²˜ë¦¬ (ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ)
                summary_html = ""
                
                if enable_article_summary and news.get('ai_summary'):
                    # ì´ë¯¸ ìƒì„±ëœ AI ìš”ì•½ ì‚¬ìš©
                    summary = news.get('ai_summary', '')
                    
                    # JSON íŒŒì‹±í•˜ì—¬ ê° ìš”ì†Œ ì¶”ì¶œ
                    try:
                        import json
                        import re
                        
                        # JSON ì‘ë‹µì—ì„œ ì½”ë“œ ë¸”ë¡ ì œê±°
                        json_text = summary.strip()
                        if "<div" in json_text:  # ì´ë¯¸ HTMLë¡œ í¬ë§·ëœ ê²½ìš°
                            summary_html = json_text
                        else:
                            # JSON íŒŒì‹± ì‹œë„
                            if json_text.startswith("```json"):
                                json_text = json_text[7:]
                            if json_text.startswith("```"):
                                json_text = "\n".join(json_text.split("\n")[1:])
                            if json_text.endswith("```"):
                                json_text = "\n".join(json_text.split("\n")[:-1])
                            
                            json_text = json_text.strip()
                            summary_data = json.loads(json_text)
                            
                            korean_title = summary_data.get('title_korean', 'ë²ˆì—­ ì œëª© ì—†ìŒ')
                            oneline_summary = summary_data.get('summary_oneline', 'ìš”ì•½ ì—†ìŒ')
                            details = summary_data.get('details', [])
                            
                            # ì„¸ë¶€ ë‚´ìš© HTML ìƒì„±
                            details_html = ""
                            if details:
                                details_html = "<ul class='details'>"
                                for detail in details:
                                    details_html += f"<li>{detail}</li>"
                                details_html += "</ul>"
                            
                            summary_html = f"""
                            <div class="korean-title">{korean_title}</div>
                            <div class="oneline-summary"><strong>í•µì‹¬ ìš”ì•½:</strong> {oneline_summary}</div>
                            {details_html}
                            """
                    except:
                        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ HTML ì‚¬ìš©
                        if summary:
                            summary_html = summary
                        else:
                            summary_html = "<div>ìš”ì•½ íŒŒì‹± ì‹¤íŒ¨</div>"
                
                elif enable_article_summary:
                    # ì›ë¬¸ ìš”ì•½ ì˜µì…˜ì´ ì¼œì ¸ìˆì§€ë§Œ ìš”ì•½ì´ ì—†ëŠ” ê²½ìš°
                    summary_html = "<div style='color: #666; font-style: italic;'>ì›ë¬¸ ìš”ì•½ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.</div>"
                else:
                    # ì›ë¬¸ ìš”ì•½ ì˜µì…˜ì´ êº¼ì ¸ìˆëŠ” ê²½ìš°
                    summary_html = "<div style='color: #666; font-style: italic;'>ì›ë¬¸ ìš”ì•½ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.</div>"
                
                # HTMLì— ê¸°ì‚¬ ì •ë³´ ì¶”ê°€
                html_content += f"""
    <div class="article">
        <div class="article-title">{i}. {title}</div>
        <div class="article-meta">
            <strong>ë‚ ì§œ:</strong> {formatted_date} | 
            <strong>ì–¸ë¡ ì‚¬:</strong> {press} | 
            <strong>í‚¤ì›Œë“œ:</strong> {source_keyword}
        </div>
        <div class="article-meta">
            <strong>ì„ ì • ì´ìœ :</strong> {reason}
        </div>
        
        {summary_html}
        
        <div class="original-url">
            <strong>ì›ë¬¸ ë§í¬:</strong> <a href="{original_url}" target="_blank">{original_url}</a>
                                    </div>
                                </div>
"""
                
                # ì§„í–‰ìƒí™© í‘œì‹œ
                st.write(f"ê¸°ì‚¬ {i}/{len(all_final_news)} ì²˜ë¦¬ ì™„ë£Œ: {title[:50]}...")
            
            # HTML ë§ˆë¬´ë¦¬
            html_content += """
    <div class="footer">
        <p>Â© 2024 PwC ë‰´ìŠ¤ ë¶„ì„ê¸° | íšŒê³„ë²•ì¸ ê´€ì ì˜ ë‰´ìŠ¤ ë¶„ì„ ë„êµ¬</p>
    </div>
</body>
</html>
"""
            
            # HTML ë‚´ìš© í‘œì‹œ
            st.markdown("#### ğŸ“‹ ìƒì„±ëœ HTML ì´ë©”ì¼")
            st.text_area(
                "HTML ì½”ë“œ (ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”)",
                value=html_content,
                height=400,
                help="ì´ HTML ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ì´ë©”ì¼ ë³¸ë¬¸ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”."
            )
            
            # HTML ë¯¸ë¦¬ë³´ê¸°
            st.markdown("#### ğŸ‘€ ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°")
            st.components.v1.html(html_content, height=600, scrolling=True)
            
            st.success(f"ğŸ‰ ì´ {len(all_final_news)}ê°œ ê¸°ì‚¬ì˜ HTML ì´ë©”ì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
        else:
        st.info("ì„ ì •ëœ ê¸°ì‚¬ê°€ ì—†ì–´ HTML ì´ë©”ì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    




else:
    # ì´ˆê¸° í™”ë©´ ì„¤ëª… (ì£¼ì„ ì²˜ë¦¬ë¨)
    """
    ### ğŸ‘‹ PwC ë‰´ìŠ¤ ë¶„ì„ê¸°ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!
    
    ì´ ë„êµ¬ëŠ” ì…ë ¥í•œ í‚¤ì›Œë“œì— ëŒ€í•œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³ , íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ì—¬ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤.
    
    #### ì£¼ìš” ê¸°ëŠ¥:
    1. ìµœì‹  ë‰´ìŠ¤ ìë™ ìˆ˜ì§‘ (ê¸°ë³¸ 100ê°œ)
    2. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ í•„í„°ë§
    3. 6ë‹¨ê³„ AI ê¸°ë°˜ ë‰´ìŠ¤ ë¶„ì„ í”„ë¡œì„¸ìŠ¤:
       - 1ë‹¨ê³„: ë‰´ìŠ¤ ìˆ˜ì§‘ - í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ìµœì‹  ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
       - 2ë‹¨ê³„: ìœ íš¨ ì–¸ë¡ ì‚¬ í•„í„°ë§ - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ ì„ ë³„
       - 3ë‹¨ê³„: ì œì™¸/ë³´ë¥˜/ìœ ì§€ íŒë‹¨ - íšŒê³„ë²•ì¸ ê´€ì ì—ì„œì˜ ì¤‘ìš”ë„ 1ì°¨ ë¶„ë¥˜
       - 4ë‹¨ê³„: ìœ ì‚¬ ë‰´ìŠ¤ ê·¸ë£¹í•‘ - ì¤‘ë³µ ê¸°ì‚¬ ì œê±° ë° ëŒ€í‘œ ê¸°ì‚¬ ì„ ì •
       - 5ë‹¨ê³„: ì¤‘ìš”ë„ í‰ê°€ ë° ìµœì¢… ì„ ì • - íšŒê³„ë²•ì¸ ê´€ì ì˜ ì¤‘ìš”ë„ í‰ê°€
       - 6ë‹¨ê³„: í•„ìš”ì‹œ ì¬í‰ê°€ - ì„ ì •ëœ ë‰´ìŠ¤ê°€ ì—†ì„ ê²½ìš° AIê°€ ê¸°ì¤€ì„ ì™„í™”í•˜ì—¬ ì¬í‰ê°€
    4. ì„ ë³„ëœ ë‰´ìŠ¤ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ ì œê³µ
       - ì œëª© ë° ë‚ ì§œ
       - ì›ë¬¸ ë§í¬
       - ì„ ë³„ ì´ìœ 
       - í‚¤ì›Œë“œ, ê´€ë ¨ ê³„ì—´ì‚¬, ì–¸ë¡ ì‚¬ ì •ë³´
    5. ë¶„ì„ ê²°ê³¼ ì´ë©”ì¼ í˜•ì‹ ë¯¸ë¦¬ë³´ê¸°
    
    #### ì‚¬ìš© ë°©ë²•:
    1. ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  ê¸°ì—…ì„ ì„ íƒí•˜ì„¸ìš” (ìµœëŒ€ 10ê°œ)
       - ê¸°ë³¸ ì œê³µ ê¸°ì—… ëª©ë¡ì—ì„œ ì„ íƒ
       - ìƒˆë¡œìš´ ê¸°ì—… ì§ì ‘ ì¶”ê°€ ê°€ëŠ¥
    2. GPT ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”
       - gpt-4o: ë¹ ë¥´ê³  ì‹¤ì‹œê°„ (ê¸°ë³¸ê°’)
    3. ë‚ ì§œ í•„í„°ë¥¼ ì„¤ì •í•˜ì„¸ìš”
       - ê¸°ë³¸ê°’: ì–´ì œ ë˜ëŠ” ì§€ë‚œ ê¸ˆìš”ì¼(ì›”ìš”ì¼ì¸ ê²½ìš°)ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€
    4. "ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
    
    #### ë¶„ì„ ê²°ê³¼ í™•ì¸:
    - ê° í‚¤ì›Œë“œë³„ ìµœì¢… ì„ ì •ëœ ì¤‘ìš” ë‰´ìŠ¤
    - ì„ ì • ê³¼ì •ì˜ ì¤‘ê°„ ê²°ê³¼(ì œì™¸/ë³´ë¥˜/ìœ ì§€, ê·¸ë£¹í•‘ ë“±)
    - ì„ ì •ëœ ëª¨ë“  ë‰´ìŠ¤ì˜ ìš”ì•½ ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°
    - ë””ë²„ê·¸ ì •ë³´ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, AI ì‘ë‹µ ë“±)
    
    """

# í‘¸í„°
st.markdown("---")
st.markdown("Â© 2024 PwC ë‰´ìŠ¤ ë¶„ì„ê¸° | íšŒê³„ë²•ì¸ ê´€ì ì˜ ë‰´ìŠ¤ ë¶„ì„ ë„êµ¬")
